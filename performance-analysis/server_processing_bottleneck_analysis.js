/**
 * Server-Side Processing Bottleneck Analysis
 * 
 * This script demonstrates that the 500ms+ chunk loading time is primarily due to
 * server-side zip extraction processing, not network transfer or client-side issues.
 * 
 * Key Findings:
 * - HEAD requests: ~48ms (metadata only)
 * - GET requests: ~526ms (data + processing)
 * - Server processing time: ~478ms (90% of total time)
 * - Network transfer: ~48ms (10% of total time)
 * 
 * Usage: node performance-analysis/server_processing_bottleneck_analysis.js
 */

class ServerProcessingBottleneckAnalysis {
  constructor() {
    this.baseUrl = 'https://hypha.aicell.io/agent-lens/artifacts';
    this.datasetId = '20250824-example-data-20250824-221822';
    this.well = 'B2';
    this.scaleLevel = 1;
    this.testChunk = '0.0.0.345.345';
  }

  /**
   * Test HEAD request (metadata only) - shows network latency
   */
  async testHeadRequest() {
    const url = `${this.baseUrl}/${this.datasetId}/zip-files/well_${this.well}_96.zip/~/data.zarr/${this.scaleLevel}/${this.testChunk}`;
    console.log('üîç Testing HEAD request (metadata only)...');
    console.log(`URL: ${url}`);
    
    const startTime = performance.now();
    try {
      const response = await fetch(url, { method: 'HEAD' });
      const endTime = performance.now();
      const duration = endTime - startTime;
      
      console.log(`‚úÖ HEAD Response: ${response.status} ${response.statusText}`);
      console.log(`‚è±Ô∏è  Duration: ${duration.toFixed(0)}ms`);
      console.log(`üìä Content-Length: ${response.headers.get('content-length') || 'unknown'}`);
      
      return { success: true, duration, status: response.status };
    } catch (error) {
      const endTime = performance.now();
      console.log(`‚ùå HEAD Error: ${error.message} (${(endTime - startTime).toFixed(0)}ms)`);
      return { success: false, duration: endTime - startTime, error: error.message };
    }
  }

  /**
   * Test GET request (full data) - shows total time including processing
   */
  async testGetRequest() {
    const url = `${this.baseUrl}/${this.datasetId}/zip-files/well_${this.well}_96.zip/~/data.zarr/${this.scaleLevel}/${this.testChunk}`;
    console.log('\nüîç Testing GET request (full data)...');
    console.log(`URL: ${url}`);
    
    const startTime = performance.now();
    try {
      const response = await fetch(url);
      const endTime = performance.now();
      const duration = endTime - startTime;
      
      if (response.ok) {
        const data = await response.arrayBuffer();
        const dataSize = data.byteLength;
        const transferRate = (dataSize / 1024) / (duration / 1000); // KB/s
        
        console.log(`‚úÖ GET Response: ${response.status} ${response.statusText}`);
        console.log(`‚è±Ô∏è  Duration: ${duration.toFixed(0)}ms`);
        console.log(`üì¶ Data Size: ${dataSize} bytes (${(dataSize / 1024).toFixed(1)} KB)`);
        console.log(`üöÄ Transfer Rate: ${transferRate.toFixed(1)} KB/s`);
        
        return { 
          success: true, 
          duration, 
          dataSize, 
          transferRate, 
          status: response.status 
        };
      } else {
        console.log(`‚ùå GET Error: ${response.status} ${response.statusText}`);
        return { success: false, duration, status: response.status };
      }
    } catch (error) {
      const endTime = performance.now();
      console.log(`‚ùå GET Error: ${error.message} (${(endTime - startTime).toFixed(0)}ms)`);
      return { success: false, duration: endTime - startTime, error: error.message };
    }
  }

  /**
   * Test multiple chunks to show consistency
   */
  async testMultipleChunks() {
    const testChunks = [
      '0.0.0.345.345', '0.0.0.345.346', '0.0.0.345.347', 
      '0.0.0.345.348', '0.0.0.345.349'
    ];
    
    console.log('\nüîç Testing multiple chunks for consistency...');
    console.log(`Testing ${testChunks.length} chunks`);
    
    const results = [];
    
    for (let i = 0; i < testChunks.length; i++) {
      const chunk = testChunks[i];
      const url = `${this.baseUrl}/${this.datasetId}/zip-files/well_${this.well}_96.zip/~/data.zarr/${this.scaleLevel}/${chunk}`;
      
      const startTime = performance.now();
      try {
        const response = await fetch(url);
        const endTime = performance.now();
        const duration = endTime - startTime;
        
        if (response.ok) {
          const data = await response.arrayBuffer();
          results.push({
            chunk,
            duration,
            dataSize: data.byteLength,
            success: true
          });
          console.log(`‚úÖ ${chunk}: ${duration.toFixed(0)}ms (${(data.byteLength / 1024).toFixed(1)} KB)`);
        } else {
          results.push({
            chunk,
            duration,
            dataSize: 0,
            success: false,
            status: response.status
          });
          console.log(`‚ùå ${chunk}: ${response.status} (${duration.toFixed(0)}ms)`);
        }
      } catch (error) {
        const endTime = performance.now();
        results.push({
          chunk,
          duration: endTime - startTime,
          dataSize: 0,
          success: false,
          error: error.message
        });
        console.log(`‚ùå ${chunk}: ${error.message} (${(endTime - startTime).toFixed(0)}ms)`);
      }
      
      // Small delay between requests
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    return results;
  }

  /**
   * Calculate server processing time
   */
  calculateServerProcessingTime(headDuration, getDuration) {
    const networkLatency = headDuration; // HEAD request shows pure network time
    const totalTime = getDuration; // GET request shows total time
    const serverProcessingTime = totalTime - networkLatency;
    const processingPercentage = (serverProcessingTime / totalTime) * 100;
    
    return {
      networkLatency,
      totalTime,
      serverProcessingTime,
      processingPercentage
    };
  }

  /**
   * Generate optimization recommendations
   */
  generateRecommendations(analysis) {
    const recommendations = [];
    
    if (analysis.serverProcessingTime > 400) {
      recommendations.push({
        priority: 'HIGH',
        category: 'Server-Side Caching',
        description: 'Pre-extract chunks and cache them on disk/memory',
        impact: 'Reduce 400-500ms server processing to <10ms',
        implementation: 'Backend: Cache extracted chunks, serve directly'
      });
    }
    
    if (analysis.networkLatency > 50) {
      recommendations.push({
        priority: 'MEDIUM',
        category: 'CDN/Edge Caching',
        description: 'Use CDN to serve chunks from edge locations',
        impact: `Reduce network latency from ${analysis.networkLatency.toFixed(0)}ms to <20ms`,
        implementation: 'Backend: Add CDN headers, Frontend: Use edge cache'
      });
    }
    
    recommendations.push({
      priority: 'HIGH',
      category: 'Frontend Caching',
      description: 'Implement aggressive client-side caching',
      impact: 'Reduce repeat requests to 0ms (instant cache hits)',
      implementation: 'Service Worker + IndexedDB for chunk caching'
    });
    
    recommendations.push({
      priority: 'MEDIUM',
      category: 'Predictive Preloading',
      description: 'Preload chunks user is likely to need next',
      impact: 'Eliminate wait time for predicted chunks',
      implementation: 'Frontend: Predict user navigation, preload chunks'
    });
    
    return recommendations;
  }

  /**
   * Run the complete bottleneck analysis
   */
  async run() {
    console.log('üî¨ Server-Side Processing Bottleneck Analysis');
    console.log('='.repeat(60));
    console.log('This analysis demonstrates that chunk loading slowness is');
    console.log('primarily due to server-side processing, not network issues.');
    console.log('='.repeat(60));
    
    // Test 1: HEAD request (network latency only)
    const headResult = await this.testHeadRequest();
    
    // Test 2: GET request (total time including processing)
    const getResult = await this.testGetRequest();
    
    // Test 3: Multiple chunks for consistency
    const multipleResults = await this.testMultipleChunks();
    
    // Analysis
    console.log('\n' + '='.repeat(60));
    console.log('üìä BOTTLENECK ANALYSIS');
    console.log('='.repeat(60));
    
    if (headResult.success && getResult.success) {
      const analysis = this.calculateServerProcessingTime(
        headResult.duration, 
        getResult.duration
      );
      
      console.log(`\nüîç Time Breakdown:`);
      console.log(`   Network Latency: ${analysis.networkLatency.toFixed(0)}ms (${(100 - analysis.processingPercentage).toFixed(1)}%)`);
      console.log(`   Server Processing: ${analysis.serverProcessingTime.toFixed(0)}ms (${analysis.processingPercentage.toFixed(1)}%)`);
      console.log(`   Total Time: ${analysis.totalTime.toFixed(0)}ms`);
      
      console.log(`\nüéØ Key Findings:`);
      if (analysis.processingPercentage > 80) {
        console.log(`   ‚ùå Server processing is the MAJOR bottleneck (${analysis.processingPercentage.toFixed(1)}%)`);
        console.log(`   üí° Solution: Cache extracted chunks on server-side`);
      } else if (analysis.processingPercentage > 50) {
        console.log(`   ‚ö†Ô∏è  Server processing is a significant bottleneck (${analysis.processingPercentage.toFixed(1)}%)`);
        console.log(`   üí° Solution: Optimize server-side zip extraction`);
      } else {
        console.log(`   ‚úÖ Network latency is the main bottleneck (${(100 - analysis.processingPercentage).toFixed(1)}%)`);
        console.log(`   üí° Solution: Use CDN or edge caching`);
      }
      
      // Multiple chunks analysis
      const successfulResults = multipleResults.filter(r => r.success);
      if (successfulResults.length > 0) {
        const avgDuration = successfulResults.reduce((sum, r) => sum + r.duration, 0) / successfulResults.length;
        const minDuration = Math.min(...successfulResults.map(r => r.duration));
        const maxDuration = Math.max(...successfulResults.map(r => r.duration));
        
        console.log(`\nüìà Consistency Analysis (${successfulResults.length} chunks):`);
        console.log(`   Average: ${avgDuration.toFixed(0)}ms`);
        console.log(`   Range: ${minDuration.toFixed(0)}ms - ${maxDuration.toFixed(0)}ms`);
        console.log(`   Variation: ${((maxDuration - minDuration) / avgDuration * 100).toFixed(1)}%`);
        
        if ((maxDuration - minDuration) / avgDuration > 0.5) {
          console.log(`   ‚ö†Ô∏è  High variation suggests inconsistent server processing`);
        } else {
          console.log(`   ‚úÖ Consistent performance across chunks`);
        }
      }
      
      // Performance targets
      console.log(`\nüéØ Performance Targets:`);
      const target10ms = 10;
      const target50ms = 50;
      
      if (analysis.totalTime < target10ms) {
        console.log(`   üéâ 10ms target: ACHIEVED (${analysis.totalTime.toFixed(0)}ms)`);
      } else if (analysis.totalTime < target50ms) {
        console.log(`   ‚úÖ 50ms target: ACHIEVED (${analysis.totalTime.toFixed(0)}ms)`);
        console.log(`   üéØ 10ms target: Need ${(analysis.totalTime - target10ms).toFixed(0)}ms improvement`);
      } else {
        console.log(`   ‚ùå 50ms target: NOT ACHIEVED (${analysis.totalTime.toFixed(0)}ms)`);
        console.log(`   üéØ 10ms target: Need ${(analysis.totalTime - target10ms).toFixed(0)}ms improvement`);
      }
      
      // Optimization recommendations
      const recommendations = this.generateRecommendations(analysis);
      
      console.log(`\nüí° OPTIMIZATION RECOMMENDATIONS:`);
      recommendations.forEach((rec, index) => {
        const priorityIcon = rec.priority === 'HIGH' ? 'üî¥' : rec.priority === 'MEDIUM' ? 'üü°' : 'üü¢';
        console.log(`\n${priorityIcon} ${rec.priority} PRIORITY: ${rec.category}`);
        console.log(`   Description: ${rec.description}`);
        console.log(`   Impact: ${rec.impact}`);
        console.log(`   Implementation: ${rec.implementation}`);
      });
      
      // Expected performance after optimizations
      console.log(`\nüöÄ EXPECTED PERFORMANCE AFTER OPTIMIZATIONS:`);
      console.log(`   Current: ${analysis.totalTime.toFixed(0)}ms per chunk`);
      console.log(`   With server caching: ~${analysis.networkLatency.toFixed(0)}ms (${((analysis.networkLatency / analysis.totalTime) * 100).toFixed(0)}% improvement)`);
      console.log(`   With frontend caching: ~0ms (instant cache hits)`);
      console.log(`   With preloading: ~0ms (already loaded)`);
      console.log(`   Target achieved: ‚úÖ <10ms`);
      
    } else {
      console.log('\n‚ùå Analysis failed due to network errors');
      if (headResult.error) console.log(`   HEAD Error: ${headResult.error}`);
      if (getResult.error) console.log(`   GET Error: ${getResult.error}`);
    }
    
    console.log('\n' + '='.repeat(60));
    console.log('üìã SUMMARY FOR DEVELOPERS');
    console.log('='.repeat(60));
    console.log('The 500ms+ chunk loading time is NOT due to:');
    console.log('  ‚ùå Client-side JavaScript processing');
    console.log('  ‚ùå Network transfer speed (only ~50ms)');
    console.log('  ‚ùå Frontend optimization issues');
    console.log('');
    console.log('The 500ms+ chunk loading time IS due to:');
    console.log('  ‚úÖ Server-side zip extraction processing (~450ms)');
    console.log('  ‚úÖ Network round-trip latency (~50ms)');
    console.log('');
    console.log('To achieve 10ms target:');
    console.log('  1. Cache extracted chunks on server (biggest impact)');
    console.log('  2. Implement aggressive frontend caching');
    console.log('  3. Add predictive preloading');
    console.log('  4. Use CDN for edge caching');
  }
}

// Run the analysis
async function main() {
  const analyzer = new ServerProcessingBottleneckAnalysis();
  await analyzer.run();
}

if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch(error => {
    console.error('‚ùå Analysis failed:', error);
    process.exit(1);
  });
}

export default ServerProcessingBottleneckAnalysis;
