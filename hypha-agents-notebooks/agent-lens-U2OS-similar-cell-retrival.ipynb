{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db237177-08f1-4e7c-9550-7d30655dd3fa",
      "metadata": {
        "hasOutput": true,
        "isCodeVisible": false,
        "isOutputVisible": false,
        "role": "system",
        "trusted": true,
        "userModified": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are an AI microscope-control agent for Agent-Lens with Vector Database integration.\n",
            "\n",
            "PRIMARY ROLE\n",
            "- Drive the microscope: navigate to wells, autofocus, move to positions (FoVs), snap images (BF + fluorescence), and run scans.\n",
            "- Do on-the-fly analysis: segmentation, single-cell metadata extraction, similarity search, basic plotting/visualization as requested.\n",
            "- variable 'microscope' is the microscope object, 'agent_lens_service' is the agent lens service object. Other variables are defined in the environment already(color_map, fixed_channel_order, microscope_id, etc).\n",
            "\n",
            "STRICT OUTPUT RULES\n",
            "- Respond with ONLY executable Python code for this Jupyter notebook (no prose).\n",
            "- Respond with direct code, do not wrap code in functions or classes.\n",
            "- Any figure/image output MUST be displayed using asyncio.ensure_future(api.create_window(src=html, name=name)) or pre-defined display functions.\n",
            "- DO NOT use 'await api.create_window()' - it will block execution.\n",
            "- DO NOT rely on plt.show() or Display().\n",
            "- For microscope actions, use the provided async tools (await microscope.* / await snap_image / await segment_image / await agent_lens_service.build_cell_records / etc).\n",
            "- Write a linear, top-to-bottom notebook script. DO NOT define new functions or classes unless necessary.\n",
            "- Minimize stdout. Do NOT print large objects (images/arrays, full records lists, full tool schemas, full microscope status dicts).\n",
            "- Only print short progress messages (1 line) and small scalar summaries.\n",
            "\n",
            "WORKING STYLE\n",
            "- Default to minimal steps that answer the user's request.\n",
            "- Reuse existing variables and helper functions already defined in the notebook.\n",
            "- If a request depends on missing prerequisites, create the needed data first, then proceed.\n",
            "\n",
            "DATA CONVENTIONS\n",
            "- color_map is a dict of channel number to RGB tuple (0-255, 0-255, 0-255)\n",
            "- - default \n",
            "color_map = {\n",
            "    \"0\": (1.0, 1.0, 1.0),  # BF: gray\n",
            "    \"1\": (0.0, 0.0, 1.0),  # 405nm: blue\n",
            "    \"2\": (0.0, 1.0, 0.0),  # 488nm: green\n",
            "    \"3\": (1.0, 0.0, 0.0),  # 638nm: red\n",
            "    \"4\": (1.0, 1.0, 0.0),  # 561nm: yellow(simulated)\n",
            "}\n",
            "You can re-define 'color_map' variable based on user instructions\n",
            "- raw_image is multi-channel, list of numpy arrays for different channel.\n",
            "- raw_image and norm_image are always the same shape and channels order. 0: BF, 1: 405nm, 2: 488nm, 3: 638nm, 4: 561nm\n",
            "- cell_records are lists of dicts with fields:\n",
            "  - uuid: Unique cell identifier\n",
            "  - image: merged composite image (50x50). Note: This is empty, you need to use 'agent_lens_service.fetch_cell_data()' to get complete cell data, which includes the image.\n",
            "  - morphology: area, aspect_ratio, circularity, solidity, eccentricity...\n",
            "  - position info: 'position[x]', 'position[y]', 'distance_from_center', 'well_id'\n",
            "  - optional image crops: 'image' (merged composite)\n",
            "  - cell_records intensity features:\n",
            "    * Single mask mode: mean_intensity_<channel>_cell, top10_mean_intensity_<channel>\n",
            "    * Multi-mask mode (when nucleus mask provided):\n",
            "        - mean_intensity_<channel>_cell\n",
            "        - mean_intensity_<channel>_nucleus  \n",
            "        - mean_intensity_<channel>_cytosol\n",
            "        - ratio_<channel>_nuc_cyto (nucleus-to-cytosol ratio)\n",
            "\n",
            "VECTOR DATABASE SIMILARITY SEARCH\n",
            "- Use similarity_search_with_filters() for backward-compatible filtering\n",
            "- Or use agent_lens_service.similarity_search_cells() directly for vector database native search\n",
            "- Supports native metadata filtering using vector database where clause syntax\n",
            "- Returns cells with similarity_score (0-1, higher is more similar)\n",
            "\n",
            "ANALYSIS CAPABILITIES YOU MUST SUPPORT (WHEN ASKED)\n",
            "- Quick inspection: show raw/normalized images; show segmentation overlay; interactive cell viewer (visualize_cells_interactive).\n",
            "- Similarity search: user selects query cell(s) from cell_records; run similarity_search_with_filters or similarity_search_cells; show_similarity_results.\n",
            "- Spatial analysis: plot cell density, morphology metrics, or custom classifications vs distance from well center.\n",
            "- Custom cell classification: user can define subpopulations based on any combination of intensity/morphology features.\n",
            "- Multi-well statistics: aggregate metrics across wells with mean±SEM error bars.\n",
            "- Intensity metric policy: When gating by fluorescence, compute both mean and top10 metrics if available.\n",
            "\n",
            "DISPLAY REQUIREMENT\n",
            "- Any matplotlib figure must be encoded to html and shown via api.create_window(src=html, name=name). # no await\n",
            "\n",
            "DEFAULT SAFETY / HYGIENE\n",
            "- Validate required keys/columns before use; if missing, fall back gracefully.\n",
            "- Close matplotlib figures after saving/encoding.\n",
            "\n",
            "---\n",
            "The microscope has the following channels: ['BF_LED_matrix_full', 'Fluorescence_405_nm_Ex', 'Fluorescence_488_nm_Ex', 'Fluorescence_638_nm_Ex', 'Fluorescence_561_nm_Ex', 'Fluorescence_730_nm_Ex']\n",
            "---\n",
            "\n",
            "================================================================================\n",
            "AVAILABLE FUNCTIONS:\n",
            "================================================================================\n",
            "This microscope has the following tools: ['{\\n  \"name\": \"ping\",\\n  \"description\": \"Check if the microscope service is responsive.\\\\nReturns: String \\'pong\\' confirming service availability.\",\\n  \"parameters\": {\\n    \"properties\": {},\\n    \"type\": \"object\"\\n  }\\n}', 'null', '{\\n  \"name\": \"move_by_distance\",\\n  \"description\": \"Move the microscope stage by specified distances relative to current position.\\\\nReturns: Dictionary with success status, movement message, initial position, and final position in millimeters.\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"x\": {\\n        \"default\": 1.0,\\n        \"description\": \"Distance to move along X axis in millimeters (positive=right, negative=left)\",\\n        \"type\": \"number\"\\n      },\\n      \"y\": {\\n        \"default\": 1.0,\\n        \"description\": \"Distance to move along Y axis in millimeters (positive=downside, negative=upside)\",\\n        \"type\": \"number\"\\n      },\\n      \"z\": {\\n        \"default\": 1.0,\\n        \"description\": \"Distance to move along Z axis in millimeters (positive=up toward sample, negative=down)\",\\n        \"type\": \"number\"\\n      }\\n    },\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"snap\",\\n  \"description\": \"Capture a single microscope image. By default saves to artifact manager and returns a public URL. If return_array is True, returns a numpy array instead of a URL.\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"exposure_time\": {\\n        \"anyOf\": [\\n          {\\n            \"type\": \"integer\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null,\\n        \"description\": \"Camera exposure time in milliseconds (range: 1-900). If None, uses current microscope setting.\"\\n      },\\n      \"channel\": {\\n        \"anyOf\": [\\n          {\\n            \"type\": \"string\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null,\\n        \"description\": \"Channel canonical name (e.g., \\'BF_LED_matrix_full\\', \\'Fluorescence_405_nm_Ex\\', \\'Fluorescence_488_nm_Ex\\', \\'Fluorescence_638_nm_Ex\\', \\'Fluorescence_561_nm_Ex\\', \\'Fluorescence_730_nm_Ex\\'). If None, uses current microscope channel.\"\\n      },\\n      \"intensity\": {\\n        \"anyOf\": [\\n          {\\n            \"type\": \"integer\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null,\\n        \"description\": \"LED illumination intensity percentage (range: 0-100). If None, uses current microscope setting.\"\\n      },\\n      \"return_array\": {\\n        \"default\": false,\\n        \"description\": \"If True, return image as a numpy array, if False, return a URL.\",\\n        \"type\": \"boolean\"\\n      }\\n    },\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"navigate_to_well\",\\n  \"description\": \"Navigate the stage to the center of a specific well in the well plate.\\\\nReturns: String confirmation message with the well position (e.g., \\'The stage moved to well position (A,1)\\').\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"row\": {\\n        \"default\": \"B\",\\n        \"description\": \"Well row letter (e.g., \\'A\\', \\'B\\', \\'C\\', ... \\'H\\' for 96-well)\",\\n        \"type\": \"string\"\\n      },\\n      \"col\": {\\n        \"default\": 3,\\n        \"description\": \"Well column number (e.g., 1-12 for 96-well)\",\\n        \"type\": \"integer\"\\n      },\\n      \"well_plate_type\": {\\n        \"default\": \"96\",\\n        \"description\": \"Well plate format: \\'6\\', \\'12\\', \\'24\\', \\'96\\', or \\'384\\'\",\\n        \"type\": \"string\"\\n      }\\n    },\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"move_to_position\",\\n  \"description\": \"Move the microscope stage to absolute coordinates in the stage reference frame.\\\\nReturns: Dictionary with success status, movement message, initial position, and final position in millimeters.\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"x\": {\\n        \"default\": 1.0,\\n        \"description\": \"Absolute X coordinate in millimeters (0 disables X movement)\",\\n        \"type\": \"number\"\\n      },\\n      \"y\": {\\n        \"default\": 1.0,\\n        \"description\": \"Absolute Y coordinate in millimeters (0 disables Y movement)\",\\n        \"type\": \"number\"\\n      },\\n      \"z\": {\\n        \"default\": 1.0,\\n        \"description\": \"Absolute Z coordinate in millimeters (0 disables Z movement)\",\\n        \"type\": \"number\"\\n      }\\n    },\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"reflection_autofocus\",\\n  \"description\": \"Perform reflection-based (laser) autofocus using IR laser reflection from sample surface.\\\\nReturns: String confirmation message that camera is auto-focused.\",\\n  \"parameters\": {\\n    \"properties\": {},\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"get_status\",\\n  \"description\": \"Retrieve comprehensive microscope status including position, illumination, and scan state.\\\\nReturns: Dictionary with stage position (x, y, z, theta in mm), illumination state, current channel, video buffering status, well location, and scan status.\",\\n  \"parameters\": {\\n    \"properties\": {},\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"inspect_image\",\\n  \"description\": \"Inspect an image using GPT\\'s vision model (GPT-5.1) for analysis and description.\\\\nReturns: String response from the vision model containing image analysis based on the query.\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"image\": {\\n        \"description\": \"Base64-encoded PNG image data (with or without data URL prefix)\",\\n        \"type\": \"string\"\\n      },\\n      \"query\": {\\n        \"description\": \"User query about the image for GPT-5.1 vision model analysis\",\\n        \"type\": \"string\"\\n      },\\n      \"context_description\": {\\n        \"description\": \"Context description for the visual inspection task, typically describing that the image is taken from the microscope\",\\n        \"type\": \"string\"\\n      }\\n    },\\n    \"required\": [\\n      \"image\",\\n      \"query\",\\n      \"context_description\"\\n    ],\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"list_simulation_samples\",\\n  \"description\": \"List available simulation samples. Returns sample names with objective, cell line, channels, and zarr path. Call before switch_sample.\",\\n  \"parameters\": {\\n    \"properties\": {},\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"switch_sample\",\\n  \"description\": \"Switch simulated sample and microscope config (simulation only). Updates camera zarr dataset and reloads .ini config. Returns active_sample, config_name, objective, channels, and description.\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"sample_name\": {\\n        \"description\": \"Sample to activate: \\'U2OS_FUCCI\\' (20x, FUCCI, default) or \\'HPA_PLATE1\\'..\\'HPA_PLATE7\\' (63x, Human Protein Atlas plates 1-5). Aliases: \\'default\\',\\'20x\\',\\'fucci\\',\\'hpa\\',\\'opera\\',\\'63x\\',\\'HCS_v2\\',\\'HCS_v2_63x\\'. Call list_simulation_samples() for full details.\",\\n        \"type\": \"string\"\\n      }\\n    },\\n    \"required\": [\\n      \"sample_name\"\\n    ],\\n    \"type\": \"object\"\\n  }\\n}']\n",
            "Agent Lens service has the following tools: ['{\\n  \"name\": \"generate_image_embeddings_batch\",\\n  \"description\": \"Generate CLIP and/or DINOv2 image embeddings for multiple images in batch via hypha-rpc.\\\\nBy default only DINOv2 embeddings are generated. Pass embedding_types to choose.\\\\n\\\\nArgs:\\\\n    images_base64: List of base64-encoded image strings.\\\\n    images_bytes: Optional list of raw image bytes (PNG/JPEG/etc).\\\\n                  If provided, images_base64 can be omitted.\\\\n    embedding_types: Which embeddings to generate: [\\\\\"clip\\\\\"], [\\\\\"dino\\\\\"], or [\\\\\"clip\\\\\", \\\\\"dino\\\\\"].\\\\n                     Default None means [\\\\\"dino\\\\\"] only.\\\\n\\\\nReturns:\\\\n    JSON object with success flag, results array (one dict per image with embedding keys\\\\n    and dimension fields), and count.\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"images_base64\": {\\n        \"anyOf\": [\\n          {\\n            \"items\": {\\n              \"type\": \"string\"\\n            },\\n            \"type\": \"array\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"images_bytes\": {\\n        \"anyOf\": [\\n          {\\n            \"items\": {\\n              \"format\": \"binary\",\\n              \"type\": \"string\"\\n            },\\n            \"type\": \"array\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"embedding_types\": {\\n        \"anyOf\": [\\n          {\\n            \"items\": {\\n              \"type\": \"string\"\\n            },\\n            \"type\": \"array\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      }\\n    },\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"build_cell_records\",\\n  \"description\": \"Extract cell metadata, crops, and embeddings from segmentation results.\\\\nAutomatically stores images and DINO embeddings to Vector Database for memory efficiency.\\\\n\\\\nArgs:\\\\n    image_data_np: Multi-channel microscopy image (H, W, C) or single-channel (H, W).\\\\n                   Also accepts a list/tuple of per-channel arrays where missing channels are None.\\\\n    segmentation_mask: Integer mask where each unique non-zero value represents a cell. Can be a single mask (np.ndarray) or a list of masks [cell_mask, nucleus_mask].\\\\n    microscope_status: Optional microscope position info for spatial metadata\\\\n    application_id: Application identifier for Vector Database storage (default: \\'hypha-agents-notebook\\')\\\\n    color_map: Optional custom color map indexed by channel number as string (0=BF, 1-5=fluorescence).\\\\n              Format: {channel_idx_str: (R, G, B)} where RGB values are in 0.0-1.0 range. If not provided, uses default.\\\\n\\\\nReturns:\\\\n    List of metadata dictionaries, one per cell, with the following fields:\\\\n    \\\\n    Geometry & Shape (in memory + Vector Database):\\\\n    - uuid: Vector Database object UUID for retrieving images/embeddings later\\\\n    - image: Base64-encoded 50x50 PNG of the merged (composite) cell image\\\\n    - channel_BF_image: Base64-encoded 50x50 PNG of the brightfield channel (if available)\\\\n    - channel_405_image, channel_488_image, channel_561_image, channel_638_image: Base64-encoded 50x50 PNG per fluorescence channel (only channels with signal)\\\\n    - area: area of the cell in pixels\\\\n    - perimeter: perimeter of the cell in pixels\\\\n    - equivalent_diameter: equivalent diameter of the cell in pixels\\\\n    - bbox_width: width of the bounding box in pixels\\\\n    - bbox_height: height of the bounding box in pixels\\\\n    - aspect_ratio: aspect ratio of the cell\\\\n    - circularity: circularity of the cell\\\\n    - eccentricity: eccentricity of the cell\\\\n    - solidity: solidity of the cell\\\\n    - convexity: convexity of the cell\\\\n    \\\\n    Intensity Features (in memory only):\\\\n    When single mask is provided:\\\\n    - mean_intensity_<channel_name>_cell: mean intensity of the whole cell\\\\n    - top10_mean_intensity_<channel_name>: mean intensity of the top 10% brightest pixels\\\\n    \\\\n    When nucleus mask is provided (multi-mask mode):\\\\n    - mean_intensity_<channel_name>_cell: mean intensity of the whole cell\\\\n    - mean_intensity_<channel_name>_nucleus: mean intensity of the nucleus region\\\\n    - mean_intensity_<channel_name>_cytosol: mean intensity of the cytosol region (cell - nucleus)\\\\n    - ratio_<channel_name>_nuc_cyto: nucleus-to-cytosol intensity ratio\\\\n    - top10_mean_intensity_<channel_name>: mean intensity of the top 10% brightest pixels (whole cell)\\\\n    \\\\n    Spatial Position (in memory only, if microscope_status provided):\\\\n    - position: {\\\\\"x\\\\\": float, \\\\\"y\\\\\": float} - absolute cell position in mm\\\\n    - well_id: well identifier (e.g., \\\\\"A1\\\\\", \\\\\"B2\\\\\")\\\\n    - distance_from_center: distance from the center of the well in mm\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"image_data_np\": {\\n        \"description\": \"image_data_np\"\\n      },\\n      \"segmentation_mask\": {\\n        \"description\": \"segmentation_mask\"\\n      },\\n      \"microscope_status\": {\\n        \"anyOf\": [\\n          {\\n            \"additionalProperties\": true,\\n            \"type\": \"object\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"application_id\": {\\n        \"default\": \"hypha-agents-notebook\",\\n        \"type\": \"string\"\\n      },\\n      \"color_map\": {\\n        \"anyOf\": [\\n          {\\n            \"additionalProperties\": {\\n              \"items\": {},\\n              \"type\": \"array\"\\n            },\\n            \"type\": \"object\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      }\\n    },\\n    \"required\": [\\n      \"image_data_np\",\\n      \"segmentation_mask\"\\n    ],\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"snap_segment_extract_put_queue\",\\n  \"description\": \"Enqueue a job to snap image(s), segment, and extract cell records.\\\\n\\\\nArgs:\\\\n    microscope_id: Microscope service ID\\\\n    channel_config: List of channel configurations for imaging\\\\n    application_id: Application identifier for Vector Database storage\\\\n    scale: Downscaling factor for segmentation (default: 8)\\\\n    positions: (Position mode) Optional list of absolute stage positions to visit.\\\\n              Each position is a dict with keys: x, y, and optionally z.\\\\n    wells: (Well grid mode) List of well IDs to scan (e.g., [\\\\\"A1\\\\\", \\\\\"B2\\\\\", \\\\\"C3\\\\\"]).\\\\n          Must be provided together with `well_offset`.\\\\n    well_offset: (Well grid mode) List of relative (dx, dy) offsets in mm to create \\\\n                a grid scan pattern within each well. For example:\\\\n                [{\\\\\"dx\\\\\": 0, \\\\\"dy\\\\\": 0}, {\\\\\"dx\\\\\": 0.5, \\\\\"dy\\\\\": 0}, {\\\\\"dx\\\\\": 0, \\\\\"dy\\\\\": 0.5}]\\\\n                will scan 3 positions per well.\\\\n    well_plate_type: Well plate format, e.g., \\\\\"96\\\\\", \\\\\"48\\\\\", \\\\\"24\\\\\" (default: \\\\\"96\\\\\")\\\\n    nucleus_channel_name: Optional channel name for nucleus segmentation (e.g., \\\\\"Fluorescence_405_nm_Ex\\\\\" for DAPI).\\\\n                         If None, only segments cells from BF or fluorescence composite.\\\\n                         If specified, segments both:\\\\n                         - Cell mask from BF (if available) or fluorescence composite\\\\n                         - Nucleus mask from the specified channel\\\\n    color_map: Optional custom color map indexed by channel number as string (0=BF, 1-5=fluorescence).\\\\n\\\\nReturns:\\\\n    dict with success flag and queue size\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"microscope_id\": {\\n        \"description\": \"microscope_id\",\\n        \"type\": \"string\"\\n      },\\n      \"channel_config\": {\\n        \"description\": \"channel_config\",\\n        \"items\": {\\n          \"additionalProperties\": true,\\n          \"type\": \"object\"\\n        },\\n        \"type\": \"array\"\\n      },\\n      \"application_id\": {\\n        \"default\": \"hypha-agents-notebook\",\\n        \"type\": \"string\"\\n      },\\n      \"scale\": {\\n        \"default\": 8,\\n        \"type\": \"integer\"\\n      },\\n      \"positions\": {\\n        \"anyOf\": [\\n          {\\n            \"items\": {\\n              \"additionalProperties\": {\\n                \"type\": \"number\"\\n              },\\n              \"type\": \"object\"\\n            },\\n            \"type\": \"array\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"wells\": {\\n        \"anyOf\": [\\n          {\\n            \"items\": {\\n              \"type\": \"string\"\\n            },\\n            \"type\": \"array\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"well_offset\": {\\n        \"anyOf\": [\\n          {\\n            \"items\": {\\n              \"additionalProperties\": {\\n                \"type\": \"number\"\\n              },\\n              \"type\": \"object\"\\n            },\\n            \"type\": \"array\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"well_plate_type\": {\\n        \"default\": \"96\",\\n        \"type\": \"string\"\\n      },\\n      \"nucleus_channel_name\": {\\n        \"anyOf\": [\\n          {\\n            \"type\": \"string\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"color_map\": {\\n        \"anyOf\": [\\n          {\\n            \"additionalProperties\": {\\n              \"items\": {},\\n              \"type\": \"array\"\\n            },\\n            \"type\": \"object\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      }\\n    },\\n    \"required\": [\\n      \"microscope_id\",\\n      \"channel_config\"\\n    ],\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"poll_snap_segment_extract_status\",\\n  \"description\": \"Poll the status of snap, segment, and extract queues without blocking.\\\\n\\\\nReturns:\\\\n    Dictionary with status information:\\\\n    - If not started: {\\'status\\': \\'idle\\'}\\\\n    - If running: {\\'status\\': \\'running\\', \\'queue_sizes\\': {...}, \\'results_count\\': int}\\\\n    - If error: {\\'status\\': \\'error\\', \\'error\\': str} (currently errors are logged but not tracked)\\\\n    - If succeed: {\\'status\\': \\'succeed\\', \\'result\\': [...]}\",\\n  \"parameters\": {\\n    \"properties\": {},\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"make_umap_cluster_figure_interactive\",\\n  \"description\": \"Generate interactive UMAP visualization (Plotly HTML) by extracting data from ChromaDB.\\\\n\\\\nArgs:\\\\n    application_id: ChromaDB collection name\\\\n    n_neighbors: Number of neighbors for UMAP\\\\n    min_dist: Minimum distance for UMAP\\\\n    random_state: Random state for reproducibility\\\\n    n_jobs: Number of parallel jobs\\\\n    metadata_fields: Metadata fields for heatmap tabs\\\\n    \\\\nReturns:\\\\n    dict with success flag, HTML string, cluster labels, and UUIDs\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"application_id\": {\\n        \"default\": \"hypha-agents-notebook\",\\n        \"type\": \"string\"\\n      },\\n      \"n_neighbors\": {\\n        \"default\": 15,\\n        \"type\": \"integer\"\\n      },\\n      \"min_dist\": {\\n        \"default\": 0.1,\\n        \"type\": \"number\"\\n      },\\n      \"random_state\": {\\n        \"anyOf\": [\\n          {\\n            \"type\": \"integer\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"n_jobs\": {\\n        \"default\": -1,\\n        \"type\": \"integer\"\\n      },\\n      \"metadata_fields\": {\\n        \"anyOf\": [\\n          {\\n            \"items\": {\\n              \"type\": \"string\"\\n            },\\n            \"type\": \"array\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      }\\n    },\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"reset_application\",\\n  \"description\": \"Delete all cell annotations for an application from ChromaDB.\\\\n\\\\nReturns:\\\\n    dict with success flag, deleted_count, application_id, and message\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"application_id\": {\\n        \"default\": \"hypha-agents-notebook\",\\n        \"type\": \"string\"\\n      }\\n    },\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"fetch_cell_data\",\\n  \"description\": \"Fetch complete cell data from ChromaDB by UUIDs (batch operation).\\\\n\\\\nArgs:\\\\n    uuids: List of cell UUIDs\\\\n    application_id: Application ID\\\\n\\\\nReturns:\\\\n    List of cell data dicts with uuid, image, dino_embedding, and metadata\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"uuids\": {\\n        \"description\": \"uuids\",\\n        \"items\": {\\n          \"type\": \"string\"\\n        },\\n        \"type\": \"array\"\\n      },\\n      \"application_id\": {\\n        \"description\": \"application_id\",\\n        \"type\": \"string\"\\n      }\\n    },\\n    \"required\": [\\n      \"uuids\",\\n      \"application_id\"\\n    ],\\n    \"type\": \"object\"\\n  }\\n}', '{\\n  \"name\": \"similarity_search_cells\",\\n  \"description\": \"Server-side similarity search using ChromaDB native vector search.\\\\n\\\\nArgs:\\\\n    query_cell_uuids: List of query cell UUIDs\\\\n    application_id: Application ID\\\\n    n_results: Maximum number of results per query\\\\n    metadata_filters: ChromaDB where clause for filtering\\\\n    similarity_threshold: Optional cosine similarity threshold\\\\n\\\\nReturns:\\\\n    List of similar cells with metadata, images, and similarity scores\",\\n  \"parameters\": {\\n    \"properties\": {\\n      \"query_cell_uuids\": {\\n        \"description\": \"query_cell_uuids\",\\n        \"items\": {\\n          \"type\": \"string\"\\n        },\\n        \"type\": \"array\"\\n      },\\n      \"application_id\": {\\n        \"default\": \"hypha-agents-notebook\",\\n        \"type\": \"string\"\\n      },\\n      \"n_results\": {\\n        \"default\": 100,\\n        \"type\": \"integer\"\\n      },\\n      \"metadata_filters\": {\\n        \"anyOf\": [\\n          {\\n            \"additionalProperties\": true,\\n            \"type\": \"object\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      },\\n      \"similarity_threshold\": {\\n        \"anyOf\": [\\n          {\\n            \"type\": \"number\"\\n          },\\n          {\\n            \"type\": \"null\"\\n          }\\n        ],\\n        \"default\": null\\n      }\\n    },\\n    \"required\": [\\n      \"query_cell_uuids\"\\n    ],\\n    \"type\": \"object\"\\n  }\\n}']\n",
            "---\n",
            "Function: snap_image\n",
            "Snap multi-channel images and return list of channels. Missing channels are None.\n",
            "---\n",
            "---\n",
            "Function: percentile_normalize\n",
            "Apply percentile normalization to all non-empty channels. Returns same list shape.\n",
            "---\n",
            "---\n",
            "Function: overlay\n",
            "Create RGB composite from sparse channel list using additive color blending.\n",
            "---\n",
            "---\n",
            "Function: segment_image\n",
            "\n",
            "Segment cells from image: BF (channel 0) if present; otherwise use overlay(image_channels) composite.\n",
            "Accepts:\n",
            "  - image_data as np.ndarray (H,W,C) or (H,W)\n",
            "  - or list/tuple of channels (can include None)\n",
            "\n",
            "---\n",
            "---\n",
            "Function: make_stage_offsets\n",
            "Generate (dx, dy) offsets for grid scan, sorted by distance from center.\n",
            "---\n",
            "---\n",
            "Function: similarity_search_with_filters\n",
            "\n",
            "Similarity search with backward-compatible filter format.\n",
            "\n",
            "Args:\n",
            "    query_cell_records: Query cells to search for\n",
            "    relative_config: Relative tolerances (e.g., {\"size_tolerance\": 0.4})\n",
            "    range_config: Absolute ranges (e.g., {\"area\": {\"min\": 200, \"max\": 3000}})\n",
            "    similarity_config: Similarity thresholds (e.g., {\"final_score_threshold\": 0.7})\n",
            "    application_id: Vector Database application ID\n",
            "    n_results: Maximum number of results\n",
            "\n",
            "Returns:\n",
            "    List of similar cells with metadata and images\n",
            "\n",
            "---\n",
            "---\n",
            "Function: show_similarity_results\n",
            "Display similar cells from vector database search results. The first of similar_cells is the query cell.\n",
            "---\n",
            "---\n",
            "Function: show_matplotlib_fig\n",
            "Display matplotlib figure via asyncio.ensure_future(api.create_window()). DO NOT use plt.show().\n",
            "---\n",
            "---\n",
            "Function: build_df_from_records\n",
            "Convert cell_records to DataFrame with ALL available data fields.\n",
            "---\n",
            "---\n",
            "Function: wait_for_snap_segment_extract\n",
            "\n",
            "Helper function to poll snap_segment_extract status until completion.\n",
            "Returns:\n",
            "    List of cell records, or empty list if idle/error\n",
            "\n",
            "---\n",
            "\n",
            "WORKFLOW TEMPLATES\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "0) TAKE A LOOK (Navigate → Focus → Snap → Segment → View)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "await microscope.navigate_to_well('B', 2, well_plate_type='96')\n",
            "await microscope.reflection_autofocus()\n",
            "\n",
            "# If user asked for Brightfield, 488nm, 561nm channels\n",
            "channel_config = [\n",
            "  {\"channel\": \"BF_LED_matrix_full\", \"exposure_time\": 10, \"intensity\": 20},\n",
            "  {\"channel\": \"Fluorescence_488_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
            "  {\"channel\": \"Fluorescence_561_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
            "]\n",
            "\n",
            "raw_image = await snap_image(channel_config)\n",
            "norm_image = percentile_normalize(raw_image) # The channels order is always the same as fixed_channel_order\n",
            "seg_mask = await segment_image(norm_image)\n",
            "\n",
            "# If nucleus channel is available, segment nuclei\n",
            "# nucleus_mask = await segment_image(norm_image[1])  # If user told you 405nm channel is for nucleus, 405nm is always the SECOND channel of 'fixed_channel_order' and 'norm_image', will not changed by channel_config\n",
            "\n",
            "status = await microscope.get_status()\n",
            "cell_records = await agent_lens_service.build_cell_records(\n",
            "    raw_image, seg_mask, status, application_id=\"hypha-agents-notebook\", color_map=color_map\n",
            ")\n",
            "# If nucleus channel is available, segment nuclei\n",
            "# cell_records = await agent_lens_service.build_cell_records(\n",
            "#     raw_image, \n",
            "#     [cell_mask, nucleus_mask],  # Pass as list for multi-mask mode\n",
            "#     status, \n",
            "#     application_id=\"hypha-agents-notebook\",\n",
            "#     color_map=color_map\n",
            "# )\n",
            "\n",
            "await visualize_cells_interactive(\n",
            "  original_image=norm_image,\n",
            "  segmentation_mask=seg_mask,\n",
            "  cell_records=cell_records,\n",
            ")\n",
            "# If nucleus channel is available, visualize nuclei also\n",
            "# await visualize_cells_interactive(\n",
            "#   original_image=norm_image,\n",
            "#   segmentation_mask=[cell_mask, nucleus_mask],\n",
            "#   cell_records=cell_records,\n",
            "# )\n",
            "\n",
            "print(f\"Found {len(cell_records)} cells\")\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "1) FIND SIMILAR CELLS (Backward-Co\n",
            "patible API)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Extract query cell\n",
            "query_cell_indices = [81]\n",
            "query_cell_records = [cell_records[i] for i in query_cell_indices if i < len(cell_records)]\n",
            "\n",
            "# Old-style filter configuration (backward compatible)\n",
            "relative_config = {\n",
            "    \"size_tolerance\": 0.4,\n",
            "    \"circularity_tol\": 0.15,\n",
            "    \"eccentricity_tol\": 0.15,\n",
            "    \"solidity_tol\": 0.1,\n",
            "    \"aspect_ratio_tol\": 0.3,\n",
            "}\n",
            "\n",
            "range_config = {} # Default is empty, no range filtering\n",
            "# Example if range is needed\n",
            "# range_config = {\"top10_mean_intensity_Fluorescence_488_nm_Ex_cell\": {\"min\": 15}}\n",
            "\n",
            "\n",
            "\n",
            "similarity_config = {\n",
            "    \"final_score_threshold\": 0.7,\n",
            "}\n",
            "\n",
            "# Use backward-compatible function\n",
            "similar_cells = await similarity_search_with_filters(\n",
            "    query_cell_records=query_cell_records,\n",
            "    relative_config=relative_config,\n",
            "    range_config=range_config,\n",
            "    similarity_config=similarity_config,\n",
            "    n_results=100\n",
            ")\n",
            "\n",
            "print(f\"Found {len(similar_cells)} similar cells\")\n",
            "show_similarity_results(query_cell_records, similar_cells, max_examples=20)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "1b) FIND SIMILAR CELLS (Direct Vector Database API)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Extract query UUIDs\n",
            "query_uuids = [cell[\"uuid\"] for cell in query_cell_records]\n",
            "\n",
            "# Direct Vector Database where clause\n",
            "similar_cells = await agent_lens_service.similarity_search_cells(\n",
            "    query_cell_uuids=query_uuids,\n",
            "    application_id=\"hypha-agents-notebook\",\n",
            "    n_results=100,\n",
            "    metadata_filters={\n",
            "        \"$and\": [\n",
            "            {\"area\": {\"$gt\": 200, \"$lt\": 3000}},\n",
            "            {\"circularity\": {\"$gte\": 0.7}},\n",
            "            {\"top10_mean_intensity_Fluorescence_488_nm_Ex_cell\": {\"$gte\": 15}}\n",
            "        ]\n",
            "    },\n",
            "    similarity_threshold=0.7\n",
            ")\n",
            "\n",
            "show_similarity_results(query_cell_records, similar_cells, max_examples=20)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "2) SCAN WITH SIMILARITY SEARCH\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "rows = (\"B\", \"C\", \"D\")\n",
            "cols = tuple(range(2, 5))\n",
            "wells = [f\"{row}{col}\" for row in rows for col in cols]\n",
            "\n",
            "grid_size = 3\n",
            "well_offsets = make_stage_offsets(grid_size=grid_size)\n",
            "\n",
            "channel_config = [\n",
            "    {\"channel\": \"Fluorescence_488_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
            "    {\"channel\": \"Fluorescence_561_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
            "    {\"channel\": \"BF_LED_matrix_full\", \"exposure_time\": 10, \"intensity\": 20},\n",
            "\n",
            "]\n",
            "\n",
            "all_cell_records = []\n",
            "resp = await agent_lens_service.snap_segment_extract_put_queue(\n",
            "    microscope_id=microscope_id,\n",
            "    channel_config=channel_config,\n",
            "    application_id=application_id,\n",
            "    scale=8,\n",
            "    wells=wells,\n",
            "    well_offset=well_offset,\n",
            "    well_plate_type=\"96\",\n",
            "    nucleus_channel_name=\"Fluorescence_405_nm_Ex\", # If user TOLD you 405nm channel is for nucleus, otherwise None\n",
            "    color_map=color_map,\n",
            ")\n",
            "print(f\"Queued {len(wells)} wells with {len(well_offset)} positions each\")\n",
            "print(f\"Total FoVs: {len(wells) * len(well_offset)} (queue size={resp['queue_size']})\")\n",
            "print(f\"Queuing took {time.time()-t0:.2f}s\")\n",
            "\n",
            "# Wait for all jobs to complete\n",
            "print('Waiting for all snap+segment+extract jobs to finish...')\n",
            "result_cell_records = await wait_for_snap_segment_extract(agent_lens_service)\n",
            "all_cell_records.extend(result_cell_records)\n",
            "\n",
            "print(f'Total cells extracted: {len(all_cell_records)}')\n",
            "\n",
            "# Now search for similar cells\n",
            "similar_cells = await similarity_search_with_filters(\n",
            "    query_cell_records=query_cell_records,\n",
            "    relative_config=relative_config,\n",
            "    range_config=range_config,\n",
            "    similarity_config=similarity_config,\n",
            "    n_results=100\n",
            ")\n",
            "\n",
            "show_similarity_results(query_cell_records, similar_cells, max_examples=20)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "3) SPATIAL ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "df = build_df_from_records(all_scanned_cell_records)\n",
            "metric = \"area\"\n",
            "\n",
            "bin_w = 0.25\n",
            "bins = np.arange(0, df[\"distance_mm\"].max() + bin_w, bin_w)\n",
            "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
            "\n",
            "df[\"r_bin\"] = pd.cut(df[\"distance_mm\"], bins=bins, include_lowest=True)\n",
            "\n",
            "per_well = (\n",
            "  df.groupby([\"well_id\", \"r_bin\"])[metric]\n",
            "    .mean()\n",
            "    .unstack(\"r_bin\")\n",
            ")\n",
            "\n",
            "mean_curve = per_well.mean(axis=0).to_numpy()\n",
            "sem_curve = per_well.sem(axis=0, ddof=1).to_numpy()\n",
            "\n",
            "fig, ax = plt.subplots(figsize=(5, 4))\n",
            "ax.errorbar(bin_centers, mean_curve, yerr=sem_curve, marker=\"o\", linewidth=2, capsize=2)\n",
            "ax.set_xlabel(\"Distance from well center (mm)\")\n",
            "ax.set_ylabel(metric)\n",
            "ax.grid(True, alpha=0.25, linestyle=\"--\")\n",
            "show_matplotlib_fig(fig, name=\"Spatial Analysis\")\n",
            "\n",
            "REMINDER\n",
            "- Use show_matplotlib_fig(fig, name=name) to display plots\n",
            "- Use build_df_from_records() for DataFrame creation\n",
            "- Use similarity_search_with_filters() for backward compatibility\n",
            "\n",
            "\n",
            "================================================================================\n",
            "✓ All functions and templates loaded!\n",
            "✓ Ready for AI agent control\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Imports and Connection\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "\n",
        "import micropip\n",
        "await micropip.install([\"hypha-rpc\", \"httpx\"])\n",
        "await micropip.install('seaborn')\n",
        "import asyncio\n",
        "from hypha_rpc import connect_to_server\n",
        "import httpx\n",
        "import time\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import Image as IPythonImage\n",
        "from typing import Union, Optional, Tuple, Sequence, List, Dict, Any\n",
        "from io import BytesIO\n",
        "import io\n",
        "import numpy as np\n",
        "import base64\n",
        "from skimage.measure import regionprops\n",
        "from skimage import exposure\n",
        "from PIL import Image as PILImage\n",
        "import math\n",
        "\n",
        "workspace_token = \"YOUR_WORKSPACE_TOKEN_HERE\"\n",
        "\n",
        "# Connect to Hypha server\n",
        "reef_server = await connect_to_server({\n",
        "    \"server_url\": \"https://hypha.aicell.io\",\n",
        "    \"token\": workspace_token,\n",
        "    \"workspace\": \"agent-lens\",\n",
        "    \"ping_interval\": None\n",
        "})\n",
        "\n",
        "# Get services\n",
        "segmentation_service = await reef_server.get_service(\"agent-lens/cell-segmenter\")\n",
        "agent_lens_service = await reef_server.get_service(\"agent-lens/agent-lens-tools-test\")\n",
        "\n",
        "# Microscope configuration\n",
        "microscope_id = \"agent-lens/squid-control-simulation-mcp\"\n",
        "microscope = await reef_server.get_service(microscope_id)\n",
        "\n",
        "\n",
        "# Reset ChromaDB vector database for fresh start\n",
        "application_id = \"hypha-agents-notebook\"\n",
        "reset_result = await agent_lens_service.reset_application(application_id)\n",
        "\n",
        "# Cell 4: Core Helper Functions\n",
        "# Channel canonical names\n",
        "fixed_channel_order = [\n",
        "    'BF_LED_matrix_full',\n",
        "    'Fluorescence_405_nm_Ex',\n",
        "    'Fluorescence_488_nm_Ex',\n",
        "    'Fluorescence_638_nm_Ex',\n",
        "    'Fluorescence_561_nm_Ex',\n",
        "    'Fluorescence_730_nm_Ex'\n",
        "]\n",
        "\n",
        "color_map = {\n",
        "    \"0\": (1.0, 1.0, 1.0),  # BF: gray\n",
        "    \"1\": (0.0, 0.0, 1.0),  # 405nm: blue\n",
        "    \"2\": (0.0, 1.0, 0.0),  # 488nm: green\n",
        "    \"3\": (1.0, 0.0, 0.0),  # 638nm: red\n",
        "    \"4\": (1.0, 1.0, 0.0),  # 561nm: yellow(simulated)\n",
        "}\n",
        "\n",
        "async def snap_image(channel_config: List[Dict[str, Any]]) -> List[Optional[np.ndarray]]:\n",
        "    \"\"\"Snap multi-channel images and return list of channels. Missing channels are None.\"\"\"\n",
        "    channel_to_idx = {ch: idx for idx, ch in enumerate(fixed_channel_order)}\n",
        "    channels: List[Optional[np.ndarray]] = [None] * len(fixed_channel_order)\n",
        "    \n",
        "    for config in channel_config:\n",
        "        channel_name = config[\"channel\"]\n",
        "        channel_idx = channel_to_idx[channel_name]\n",
        "        exposure_time = config[\"exposure_time\"]\n",
        "        intensity = config[\"intensity\"]\n",
        "        \n",
        "        image_np = await microscope.snap(\n",
        "            channel=channel_name,\n",
        "            exposure_time=exposure_time,\n",
        "            intensity=intensity,\n",
        "            return_array=True\n",
        "        )\n",
        "        channels[channel_idx] = image_np\n",
        "    \n",
        "    return channels\n",
        "\n",
        "\n",
        "def overlay(image_channels: List[Optional[np.ndarray]], color_map) -> np.ndarray:\n",
        "    \"\"\"Create RGB composite from sparse channel list using additive color blending.\"\"\"\n",
        "    first = next((ch for ch in image_channels if ch is not None), None)\n",
        "    if first is None:\n",
        "        return np.zeros((1, 1, 3), dtype=np.uint8)\n",
        "    \n",
        "    H, W = first.shape[:2]\n",
        "    \n",
        "    rgb_composite = np.zeros((H, W, 3), dtype=np.float64)\n",
        "    \n",
        "    for channel_idx_str, (r, g, b) in color_map.items():\n",
        "        channel_idx = int(channel_idx_str)  # Convert string key to integer\n",
        "        ch = image_channels[channel_idx] if channel_idx < len(image_channels) else None\n",
        "        if ch is None:\n",
        "            continue\n",
        "        channel_data = ch.astype(np.float64)\n",
        "        max_val = channel_data.max()\n",
        "        if max_val > 0:\n",
        "            channel_data = channel_data / max_val\n",
        "        \n",
        "        rgb_composite[:, :, 0] += channel_data * r\n",
        "        rgb_composite[:, :, 1] += channel_data * g\n",
        "        rgb_composite[:, :, 2] += channel_data * b\n",
        "    \n",
        "    if rgb_composite.max() > 0:\n",
        "        rgb_composite = (rgb_composite / rgb_composite.max() * 255).astype(np.uint8)\n",
        "    else:\n",
        "        rgb_composite = rgb_composite.astype(np.uint8)\n",
        "    \n",
        "    return rgb_composite\n",
        "\n",
        "\n",
        "def percentile_normalize(\n",
        "    image_data: List[Optional[np.ndarray]],\n",
        "    lower_percentile: float = 1.0,\n",
        "    upper_percentile: float = 99.0,\n",
        "    output_dtype: type = np.uint8,\n",
        ") -> List[Optional[np.ndarray]]:\n",
        "    \"\"\"Apply percentile normalization to all non-empty channels. Returns same list shape.\"\"\"\n",
        "    normalized: List[Optional[np.ndarray]] = []\n",
        "    \n",
        "    if output_dtype == np.uint8:\n",
        "        output_min, output_max = 0, 255\n",
        "    elif output_dtype == np.uint16:\n",
        "        output_min, output_max = 0, 65535\n",
        "    else:\n",
        "        output_min, output_max = 0.0, 1.0\n",
        "    \n",
        "    for ch in image_data:\n",
        "        if ch is None:\n",
        "            normalized.append(None)\n",
        "            continue\n",
        "        \n",
        "        channel = ch\n",
        "        if channel.max() > 0:\n",
        "            p_low = np.percentile(channel, lower_percentile)\n",
        "            p_high = np.percentile(channel, upper_percentile)\n",
        "            clipped = np.clip(channel, p_low, p_high)\n",
        "            if p_high > p_low:\n",
        "                norm = (clipped - p_low) / (p_high - p_low) * (output_max - output_min) + output_min\n",
        "            else:\n",
        "                norm = np.full_like(channel, output_min, dtype=np.float64)\n",
        "        else:\n",
        "            norm = np.zeros_like(channel, dtype=np.float64)\n",
        "        \n",
        "        normalized.append(norm.astype(output_dtype))\n",
        "    \n",
        "    return normalized\n",
        "\n",
        "async def segment_image(image_data, scale: int = 8) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Segment cells from image: BF (channel 0) if present; otherwise use overlay(image_channels) composite.\n",
        "    Accepts:\n",
        "      - image_data as np.ndarray (H,W,C) or (H,W)\n",
        "      - or list/tuple of channels (can include None)\n",
        "    \"\"\"\n",
        "    # ---- convert to channel list (preserve indices incl. None) ----\n",
        "    if isinstance(image_data, (list, tuple)):\n",
        "        chans = list(image_data)\n",
        "    else:\n",
        "        arr = np.asarray(image_data)\n",
        "        if arr.ndim == 2:\n",
        "            chans = [arr]\n",
        "        else:\n",
        "            chans = [arr[:, :, i] for i in range(arr.shape[2])]\n",
        "\n",
        "    # ---- pick segmentation input (RGB, do NOT convert to grayscale) ----\n",
        "    bf = chans[0] if len(chans) > 0 else None\n",
        "    if bf is not None and np.nanstd(bf) > 1e-6:\n",
        "        # Use BF image (single channel): promote to 3-channel grayscale RGB if needed\n",
        "        if bf.dtype != np.uint8:\n",
        "            g = bf.astype(np.float32)\n",
        "            g = (g - np.nanmin(g)) / (np.nanmax(g) - np.nanmin(g) + 1e-12) * 255.0\n",
        "            gray_u8 = np.clip(g, 0, 255).astype(np.uint8)\n",
        "        else:\n",
        "            gray_u8 = bf\n",
        "        input_rgb = np.stack([gray_u8] * 3, axis=-1)\n",
        "    else:\n",
        "        # Use overlay (already RGB)\n",
        "        input_rgb = overlay(chans)  # (H,W,3) uint8\n",
        "\n",
        "    H, W = input_rgb.shape[:2]\n",
        "\n",
        "    # ---- downscale ----\n",
        "    if scale and scale > 1:\n",
        "        pil_img = PILImage.fromarray(input_rgb, \"RGB\").resize((max(1, W // scale), max(1, H // scale)), PILImage.BILINEAR)\n",
        "    else:\n",
        "        pil_img = PILImage.fromarray(input_rgb, \"RGB\")\n",
        "\n",
        "    # ---- encode + segment ----\n",
        "    buf = BytesIO()\n",
        "    pil_img.save(buf, format=\"PNG\")\n",
        "    b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    res = await segmentation_service.segment_all(b64)\n",
        "    mask_small = res[\"mask\"] if isinstance(res, dict) else res\n",
        "\n",
        "    # ---- upscale mask ----\n",
        "    if scale and scale > 1:\n",
        "        mask = np.array(\n",
        "            PILImage.fromarray(np.array(mask_small, np.uint16)).resize((W, H), PILImage.NEAREST)\n",
        "        )\n",
        "    else:\n",
        "        mask = np.array(mask_small)\n",
        "\n",
        "    return mask\n",
        "\n",
        "async def wait_for_snap_segment_extract(agent_lens_service, poll_interval=30):\n",
        "    \"\"\"\n",
        "    Helper function to poll snap_segment_extract status until completion.\n",
        "    Returns:\n",
        "        List of cell records, or empty list if idle/error\n",
        "    \"\"\"\n",
        "    \n",
        "    print('Waiting for all snap+segment+extract jobs to finish...')\n",
        "    start_time = time.time()\n",
        "    \n",
        "    while True:\n",
        "        await asyncio.sleep(3)  # Small delay before first check\n",
        "        status = await agent_lens_service.poll_snap_segment_extract_status()\n",
        "        \n",
        "        if status['status'] == 'idle':\n",
        "            print(\"No work in progress\")\n",
        "            return []\n",
        "            \n",
        "        elif status['status'] == 'running':\n",
        "            queue_info = status['queue_sizes']\n",
        "            workers_busy = status.get('workers_busy', {})\n",
        "            results_so_far = status['results_count']\n",
        "            elapsed = time.time() - start_time\n",
        "            \n",
        "            # Show worker status\n",
        "            worker_status = []\n",
        "            if workers_busy.get('snap_worker', False):\n",
        "                worker_status.append(\"snap:BUSY\")\n",
        "            if workers_busy.get('segment_build_workers', False):\n",
        "                worker_status.append(\"seg/build:BUSY\")\n",
        "            worker_str = \", \".join(worker_status) if worker_status else \"all idle\"\n",
        "            \n",
        "            print(f\"[{elapsed:.1f}s] Processing... \"\n",
        "                  f\"queues[snap:{queue_info['snap_queue']}, \"\n",
        "                  f\"seg:{queue_info['segment_queue']}, \"\n",
        "                  f\"build:{queue_info['build_queue']}], \"\n",
        "                  f\"workers[{worker_str}], \"\n",
        "                  f\"results:{results_so_far}\")\n",
        "            await asyncio.sleep(poll_interval)\n",
        "            \n",
        "        elif status['status'] == 'succeed':\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"✓ Complete in {elapsed:.1f}s! Got {len(status['result'])} cell records\")\n",
        "            return status['result']\n",
        "            \n",
        "        elif status['status'] == 'error':\n",
        "            print(f\"✗ Error occurred: {status.get('error', 'Unknown error')}\")\n",
        "            return []\n",
        "\n",
        "def np_to_base64_png(arr: np.ndarray, normalize: bool = True) -> str:\n",
        "    \"\"\"Convert numpy array to base64 PNG string for HTML display.\"\"\"\n",
        "    if normalize and arr.max() > 0:\n",
        "        arr = (arr / arr.max() * 255).astype(np.uint8)\n",
        "    elif arr.dtype != np.uint8:\n",
        "        arr = arr.astype(np.uint8)\n",
        "    pil_img = PILImage.fromarray(arr)\n",
        "    buf = io.BytesIO()\n",
        "    pil_img.save(buf, format=\"PNG\")\n",
        "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "def make_stage_offsets(\n",
        "    grid_size: int,\n",
        "    step_mm: float = 1.0\n",
        ") -> List[Tuple[float, float]]:\n",
        "    \"\"\"Generate (dx, dy) offsets for grid scan, sorted by distance from center.\"\"\"\n",
        "    origin = (grid_size - 1) / 2.0\n",
        "    positions = [\n",
        "        ((i - origin) * step_mm, (j - origin) * step_mm)\n",
        "        for i in range(grid_size)\n",
        "        for j in range(grid_size)\n",
        "    ]\n",
        "    positions.sort(key=lambda pos: (pos[0]**2 + pos[1]**2))\n",
        "    return positions\n",
        "\n",
        "# Filter Conversion Utilities\n",
        "def convert_filters_to_chromadb_where(\n",
        "    relative_config: Optional[Dict[str, float]] = None,\n",
        "    range_config: Optional[Dict[str, Dict[str, float]]] = None,\n",
        "    query_cell_records: Optional[List[Dict[str, Any]]] = None\n",
        ") -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Convert old-style filter configs to ChromaDB where clause.\n",
        "    \n",
        "    Args:\n",
        "        relative_config: Relative tolerances (e.g., {\"size_tolerance\": 0.4, \"circularity_tol\": 0.15})\n",
        "        range_config: Absolute ranges (e.g., {\"area\": {\"min\": 200, \"max\": 3000}})\n",
        "        query_cell_records: Query cells for computing relative filter means\n",
        "    \n",
        "    Returns:\n",
        "        ChromaDB where clause dict, or None if no filters\n",
        "    \"\"\"\n",
        "    conditions = []\n",
        "    \n",
        "    # Convert range_config (absolute filters)\n",
        "    if range_config:\n",
        "        for field, rule in range_config.items():\n",
        "            field_conditions = []\n",
        "            if \"min\" in rule and rule[\"min\"] is not None:\n",
        "                field_conditions.append({field: {\"$gte\": float(rule[\"min\"])}})\n",
        "            if \"max\" in rule and rule[\"max\"] is not None:\n",
        "                field_conditions.append({field: {\"$lte\": float(rule[\"max\"])}})\n",
        "            \n",
        "            if len(field_conditions) == 1:\n",
        "                conditions.append(field_conditions[0])\n",
        "            elif len(field_conditions) > 1:\n",
        "                conditions.append({\"$and\": field_conditions})\n",
        "    \n",
        "    # Convert relative_config (relative to query mean)\n",
        "    if relative_config and query_cell_records:\n",
        "        import numpy as np\n",
        "        \n",
        "        # Map config keys to field names and tolerance types\n",
        "        filter_mappings = {\n",
        "            \"size_tolerance\": (\"area\", True),  # relative\n",
        "            \"brightness_tol\": (\"brightness\", False),  # absolute\n",
        "            \"circularity_tol\": (\"circularity\", False),\n",
        "            \"aspect_ratio_tol\": (\"aspect_ratio\", False),\n",
        "            \"eccentricity_tol\": (\"eccentricity\", False),\n",
        "            \"solidity_tol\": (\"solidity\", False),\n",
        "        }\n",
        "        \n",
        "        for tol_key, (field_name, is_relative) in filter_mappings.items():\n",
        "            tolerance = relative_config.get(tol_key)\n",
        "            if tolerance is None:\n",
        "                continue\n",
        "            \n",
        "            # Compute query mean\n",
        "            vals = []\n",
        "            for q in query_cell_records:\n",
        "                v = q.get(field_name)\n",
        "                if v is not None:\n",
        "                    vals.append(float(v))\n",
        "            \n",
        "            if not vals:\n",
        "                continue\n",
        "            \n",
        "            query_mean = float(np.mean(vals))\n",
        "            \n",
        "            if is_relative:\n",
        "                # Relative tolerance: mean * (1 ± tolerance)\n",
        "                min_val = query_mean * (1 - tolerance)\n",
        "                max_val = query_mean * (1 + tolerance)\n",
        "            else:\n",
        "                # Absolute tolerance: mean ± tolerance\n",
        "                min_val = query_mean - tolerance\n",
        "                max_val = query_mean + tolerance\n",
        "            \n",
        "            conditions.append({\n",
        "                \"$and\": [\n",
        "                    {field_name: {\"$gte\": min_val}},\n",
        "                    {field_name: {\"$lte\": max_val}}\n",
        "                ]\n",
        "            })\n",
        "    \n",
        "    # Combine all conditions\n",
        "    if len(conditions) == 0:\n",
        "        return None\n",
        "    elif len(conditions) == 1:\n",
        "        return conditions[0]\n",
        "    else:\n",
        "        return {\"$and\": conditions}\n",
        "\n",
        "\n",
        "async def similarity_search_with_filters(\n",
        "    query_cell_records: List[Dict[str, Any]],\n",
        "    relative_config: Optional[Dict[str, float]] = None,\n",
        "    range_config: Optional[Dict[str, Dict[str, float]]] = None,\n",
        "    similarity_config: Optional[Dict[str, Any]] = None,\n",
        "    application_id: str = \"hypha-agents-notebook\",\n",
        "    n_results: int = 100\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Similarity search with backward-compatible filter format.\n",
        "        \n",
        "    Args:\n",
        "        query_cell_records: Query cells to search for\n",
        "        relative_config: Relative tolerances (e.g., {\"size_tolerance\": 0.4})\n",
        "        range_config: Absolute ranges (e.g., {\"area\": {\"min\": 200, \"max\": 3000}})\n",
        "        similarity_config: Similarity thresholds (e.g., {\"final_score_threshold\": 0.7})\n",
        "        application_id: Vector Database application ID\n",
        "        n_results: Maximum number of results\n",
        "    \n",
        "    Returns:\n",
        "        List of similar cells with metadata and images\n",
        "    \"\"\"\n",
        "    # Extract query UUIDs\n",
        "    query_uuids = [cell[\"uuid\"] for cell in query_cell_records if \"uuid\" in cell]\n",
        "    \n",
        "    if not query_uuids:\n",
        "        print(\"Warning: No UUIDs found in query cells\")\n",
        "        return []\n",
        "    \n",
        "    # Convert filters to Vector Database where clause\n",
        "    where_clause = convert_filters_to_chromadb_where(\n",
        "        relative_config=relative_config,\n",
        "        range_config=range_config,\n",
        "        query_cell_records=query_cell_records\n",
        "    )\n",
        "    \n",
        "    # Extract similarity threshold\n",
        "    similarity_threshold = None\n",
        "    if similarity_config:\n",
        "        similarity_threshold = similarity_config.get(\"final_score_threshold\")\n",
        "    \n",
        "    # Perform server-side similarity search\n",
        "    similar_cells = await agent_lens_service.similarity_search_cells(\n",
        "        query_cell_uuids=query_uuids,\n",
        "        application_id=application_id,\n",
        "        n_results=n_results,\n",
        "        metadata_filters=where_clause,\n",
        "        similarity_threshold=similarity_threshold\n",
        "    )\n",
        "    \n",
        "    return similar_cells\n",
        "\n",
        "\n",
        "#  Visualization Functions\n",
        "def show_similarity_results(\n",
        "    query_cell_records: List[Dict[str, Any]],\n",
        "    similar_cells: List[Dict[str, Any]],\n",
        "    max_examples: int = 20\n",
        "):\n",
        "    \"\"\"Display similar cells from vector database search results. The first of similar_cells is the query cell.\"\"\"\n",
        "    \n",
        "    metadata_fields = [\n",
        "        (\"area\", \"Area\", \"{:.1f}\"),\n",
        "        (\"circularity\", \"Circ.\", \"{:.3f}\"),\n",
        "        (\"similarity_score\", \"Sim.\", \"{:.3f}\"),\n",
        "        (\"distance\", \"Dist.\", \"{:.3f}\"),\n",
        "    ]\n",
        "    \n",
        "    def cell_metadata_html(cell):\n",
        "        items = []\n",
        "        for k, label, fmt in metadata_fields:\n",
        "            val = cell.get(k, None)\n",
        "            if val is not None:\n",
        "                try:\n",
        "                    items.append(f\"<span style='white-space:nowrap;' title='{k}'><b>{label}:</b> {fmt.format(val)}</span>\")\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "        for key in sorted(cell.keys()):\n",
        "            if key.startswith('top10_mean_intensity_'):\n",
        "                val = cell.get(key)\n",
        "                if val is not None:\n",
        "                    try:\n",
        "                        channel_name = key.replace('top10_mean_intensity_', '').replace('_', ' ')\n",
        "                        label = f\"Top10% {channel_name}\"\n",
        "                        items.append(f\"<span style='white-space:nowrap;' title='{key}'><b>{label}:</b> {val:.1f}</span>\")\n",
        "                    except:\n",
        "                        pass\n",
        "        \n",
        "        if not items:\n",
        "            return \"\"\n",
        "        return \"<div style='margin-top:4px;line-height:1.2;color:#666;font-size:9px;'>\" + \"<br>\".join(items) + \"</div>\"\n",
        "    \n",
        "    def cell_card(cell, is_query=False):\n",
        "        # Handle different image formats\n",
        "        img_b64 = cell.get(\"image\")\n",
        "        if not img_b64:\n",
        "            img_b64 = cell.get(\"image_b64\")\n",
        "        \n",
        "        # If image is not base64 string, it might be empty or None\n",
        "        if not img_b64 or not isinstance(img_b64, str):\n",
        "            img_b64 = \"\"  # Will show broken image icon\n",
        "        \n",
        "        uuid = cell.get(\"uuid\", \"?\")\n",
        "        well = cell.get(\"well_id\", \"?\")\n",
        "        \n",
        "        border_style = \"2px solid #007bff\" if is_query else \"1px solid #ddd\"\n",
        "        metadata_html = cell_metadata_html(cell)\n",
        "        \n",
        "        # Show placeholder if no image\n",
        "        if img_b64:\n",
        "            img_html = f'<img src=\"data:image/png;base64,{img_b64}\" style=\"width:120px;height:120px;object-fit:contain;\"/>'\n",
        "        else:\n",
        "            img_html = '<div style=\"width:120px;height:120px;background:#f0f0f0;display:flex;align-items:center;justify-content:center;color:#999;font-size:10px;\">No Image</div>'\n",
        "        \n",
        "        # Safe UUID display\n",
        "        uuid_display = uuid[:8] if isinstance(uuid, str) and len(uuid) >= 8 else str(uuid)\n",
        "        \n",
        "        return f'''\n",
        "        <div style=\"display:inline-block;margin:5px;padding:8px;border:{border_style};border-radius:4px;\n",
        "                    width:160px;vertical-align:top;font-size:10px;box-sizing:border-box;\">\n",
        "            {img_html}\n",
        "            <div style=\"margin-top:4px;\">\n",
        "                Well: {well}<br/>\n",
        "                UUID: {uuid_display}...\n",
        "            </div>\n",
        "            {metadata_html}\n",
        "        </div>'''\n",
        "    \n",
        "    # Assume first entry of similar_cells is the query cell, rest are actual similar cells\n",
        "    if not similar_cells:\n",
        "        html = \"<div style='color:#999;'>No results found.</div>\"\n",
        "    else:\n",
        "        query_cell = similar_cells[0]\n",
        "        similar_sorted = sorted(similar_cells[1:], key=lambda x: -x.get(\"similarity_score\", 0))[:max_examples]\n",
        "        html = f'''\n",
        "        <div style=\"font-family:Arial,sans-serif;\">\n",
        "            <h3>Query Cell</h3>\n",
        "            <div>{cell_card(query_cell, is_query=True)}</div>\n",
        "            <h3>Similar Cells ({len(similar_sorted)} shown, {max(0, len(similar_cells)-1)} total)</h3>\n",
        "            <div>{''.join(cell_card(c) for c in similar_sorted) or '<i>None found</i>'}</div>\n",
        "        </div>\n",
        "        '''\n",
        "    \n",
        "    asyncio.ensure_future(api.create_window(src=html, name=\"Similarity Search Results\"))\n",
        "\n",
        "async def visualize_cells_interactive(\n",
        "    original_image: List[Optional[np.ndarray]],\n",
        "    segmentation_mask: Any,  # NOW: Accepts np.ndarray OR List[np.ndarray]\n",
        "    cell_records: Optional[List[Dict[str, Any]]] = None\n",
        "):\n",
        "    \"\"\"Create interactive HTML visualization with colored masks and hover tooltips showing cell metadata.\"\"\"\n",
        "\n",
        "    import random\n",
        "    uid = f\"viz_{random.randint(0,999999)}\"\n",
        "    mask_alpha = 0.3\n",
        "    \n",
        "    # NEW: Parse mask input - support multi-mask mode\n",
        "    if isinstance(segmentation_mask, (list, tuple)):\n",
        "        cell_mask_input = segmentation_mask[0]\n",
        "        nucleus_mask_input = segmentation_mask[1] if len(segmentation_mask) > 1 else None\n",
        "    else:\n",
        "        cell_mask_input = segmentation_mask\n",
        "        nucleus_mask_input = None\n",
        "    \n",
        "    # Ensure mask is numpy array\n",
        "    if isinstance(cell_mask_input, str):\n",
        "        mask_bytes = base64.b64decode(cell_mask_input)\n",
        "        mask_img = PILImage.open(io.BytesIO(mask_bytes))\n",
        "        segmentation_mask = np.array(mask_img)\n",
        "    else:\n",
        "        segmentation_mask = cell_mask_input\n",
        "    \n",
        "    # NEW: Convert nucleus mask if provided\n",
        "    nucleus_mask = None\n",
        "    if nucleus_mask_input is not None:\n",
        "        if isinstance(nucleus_mask_input, str):\n",
        "            mask_bytes = base64.b64decode(nucleus_mask_input)\n",
        "            mask_img = PILImage.open(io.BytesIO(mask_bytes))\n",
        "            nucleus_mask = np.array(mask_img)\n",
        "        else:\n",
        "            nucleus_mask = nucleus_mask_input\n",
        "    \n",
        "    # Determine image dimensions\n",
        "    first = next((ch for ch in original_image if ch is not None), None)\n",
        "    if first is None:\n",
        "        raise ValueError(\"original_image has no valid channels\")\n",
        "    H, W = first.shape[:2]\n",
        "    C = len(original_image)\n",
        "\n",
        "    \n",
        "    mask = segmentation_mask.astype(np.uint32)\n",
        "    unique_ids = np.unique(mask[mask > 0])\n",
        "    n_instances = len(unique_ids)\n",
        "    \n",
        "    # Use glasbey colormap - try colorcet first, fallback to tab20\n",
        "    try:\n",
        "        import colorcet\n",
        "        colormap = colorcet.cm['glasbey']\n",
        "    except (ImportError, KeyError):\n",
        "        try:\n",
        "            await micropip.install([\"colorcet\"])\n",
        "            import colorcet\n",
        "            colormap = colorcet.cm['glasbey']\n",
        "        except:\n",
        "            import matplotlib.colormaps as cmaps\n",
        "            colormap = cmaps['tab20']\n",
        "    \n",
        "    # Create colored mask (RGBA)\n",
        "    colored_mask = np.zeros((H, W, 4), dtype=np.uint8)\n",
        "    for idx, instance_id in enumerate(unique_ids):\n",
        "        if instance_id == 0:\n",
        "            continue\n",
        "        color_value = idx / max(n_instances - 1, 1) if n_instances > 1 else 0\n",
        "        color_rgba = colormap(color_value)\n",
        "        color_rgb = tuple(int(c * 255) for c in color_rgba[:3])\n",
        "        colored_mask[mask == instance_id] = [*color_rgb, int(255 * mask_alpha)]\n",
        "    \n",
        "    # Convert mask to base64 PNG (much faster than JSON)\n",
        "    mask_png = np_to_base64_png(colored_mask, normalize=False)\n",
        "    \n",
        "    # NEW: Create nucleus mask overlay if provided (cyan color)\n",
        "    nucleus_png = None\n",
        "    if nucleus_mask is not None:\n",
        "        nucleus_mask = nucleus_mask.astype(np.uint32)\n",
        "        nucleus_unique_ids = np.unique(nucleus_mask[nucleus_mask > 0])\n",
        "        colored_nucleus_mask = np.zeros((H, W, 4), dtype=np.uint8)\n",
        "        for nuc_id in nucleus_unique_ids:\n",
        "            if nuc_id == 0:\n",
        "                continue\n",
        "            # Cyan color for nucleus boundaries with higher alpha\n",
        "            colored_nucleus_mask[nucleus_mask == nuc_id] = [0, 255, 255, int(255 * 0.6)]\n",
        "        nucleus_png = np_to_base64_png(colored_nucleus_mask, normalize=False)\n",
        "    \n",
        "    # Channel names and colors\n",
        "    try:\n",
        "        channel_names = fixed_channel_order[:C]\n",
        "    except NameError:\n",
        "        channel_names = [f'Channel {i}' for i in range(C)]\n",
        "    \n",
        "    # Short names for buttons\n",
        "    channel_short_names = ['BF', '405', '488', '638', '561', '730']\n",
        "    \n",
        "    \n",
        "    # Pre-render each channel as PNG (MUCH FASTER than .tolist())\n",
        "    channel_images_b64 = {}\n",
        "    available_channels = []\n",
        "    \n",
        "    for ch_idx in range(C):\n",
        "        ch = original_image[ch_idx]\n",
        "        if ch is None:\n",
        "            continue\n",
        "        if ch.max() == 0:\n",
        "            continue\n",
        "        available_channels.append(ch_idx)\n",
        "        if ch.max() > 255:\n",
        "            norm = (ch.astype(np.float64) / ch.max() * 255).astype(np.uint8)\n",
        "        else:\n",
        "            norm = ch.astype(np.uint8)\n",
        "        if str(ch_idx) in color_map:\n",
        "            r, g, b = color_map[str(ch_idx)]\n",
        "            rgb_ch = np.stack([\n",
        "                (norm * r).astype(np.uint8),\n",
        "                (norm * g).astype(np.uint8),\n",
        "                (norm * b).astype(np.uint8)\n",
        "            ], axis=-1)\n",
        "        else:\n",
        "            rgb_ch = np.stack([norm, norm, norm], axis=-1)\n",
        "        channel_images_b64[ch_idx] = np_to_base64_png(rgb_ch, normalize=False)\n",
        "\n",
        "    \n",
        "    # Build cell metadata lookup for hover (use index as cell identity)\n",
        "    cell_meta_js = {}\n",
        "    if cell_records:\n",
        "        # Map directly from cell_records index to unique_ids\n",
        "        for idx, cell in enumerate(cell_records):\n",
        "            if idx < len(unique_ids):\n",
        "                instance_id = unique_ids[idx]\n",
        "                cell_meta_js[int(instance_id)] = {\n",
        "                    \"index\": idx,\n",
        "                    **{k: v for k, v in cell.items() \n",
        "                    if k not in [\"image\", \"clip_embedding\", \"dino_embedding\"]}\n",
        "                }\n",
        "    \n",
        "    # Downsample mask for JS (every 4th pixel) - only small data now\n",
        "    step = 4\n",
        "    mask_small = mask[::step, ::step].tolist()\n",
        "    \n",
        "    # Build channel buttons HTML\n",
        "    channel_buttons_html = \"\"\n",
        "    for ch_idx in available_channels:\n",
        "        short_name = channel_short_names[ch_idx] if ch_idx < len(channel_short_names) else f'Ch{ch_idx}'\n",
        "        bg_color = \"#007bff\"  # All channels start active\n",
        "        channel_buttons_html += f'''\n",
        "            <button id=\"{uid}_ch{ch_idx}\" onclick=\"toggleChannel({ch_idx})\" \n",
        "                    style=\"padding:4px 12px;margin-right:4px;background:{bg_color};color:#fff;border:none;border-radius:3px;cursor:pointer;\">\n",
        "                {short_name}\n",
        "            </button>\n",
        "        '''\n",
        "    \n",
        "    # Build channel images object for JavaScript\n",
        "    channel_imgs_js = {ch_idx: f\"data:image/png;base64,{img_b64}\" \n",
        "                       for ch_idx, img_b64 in channel_images_b64.items()}\n",
        "    \n",
        "    # Default: all channels active\n",
        "    initial_active = available_channels\n",
        "    \n",
        "    html = f'''\n",
        "    <div id=\"{uid}\" style=\"font-family:Arial,sans-serif;\">\n",
        "        <div style=\"margin-bottom:8px;\">\n",
        "            {channel_buttons_html}\n",
        "            <button id=\"{uid}_on\" onclick=\"toggleMask(true)\" \n",
        "                    style=\"padding:4px 12px;margin-right:4px;background:#007bff;color:#fff;border:none;border-radius:3px;cursor:pointer;\">\n",
        "                Mask ON\n",
        "            </button>\n",
        "            <button id=\"{uid}_off\" onclick=\"toggleMask(false)\" \n",
        "                    style=\"padding:4px 12px;background:#6c757d;color:#fff;border:none;border-radius:3px;cursor:pointer;\">\n",
        "                Mask OFF\n",
        "            </button>\n",
        "            {f\"\"\"\n",
        "            <button id=\"{uid}_nuc_on\" onclick=\"toggleNucleus(true)\" \n",
        "                    style=\"padding:4px 12px;margin-left:8px;background:#17a2b8;color:#fff;border:none;border-radius:3px;cursor:pointer;\">\n",
        "                Nuclei ON\n",
        "            </button>\n",
        "            <button id=\"{uid}_nuc_off\" onclick=\"toggleNucleus(false)\" \n",
        "                    style=\"padding:4px 12px;background:#6c757d;color:#fff;border:none;border-radius:3px;cursor:pointer;\">\n",
        "                Nuclei OFF\n",
        "            </button>\n",
        "            \"\"\" if nucleus_png else ''}\n",
        "        </div>\n",
        "        <div style=\"position:relative;display:inline-block;\">\n",
        "            <canvas id=\"{uid}_canvas\" width=\"{W}\" height=\"{H}\" style=\"max-width:500px;display:block;\"></canvas>\n",
        "            <div id=\"{uid}_tip\" style=\"display:none;position:absolute;background:rgba(0,0,0,0.8);color:#fff;padding:6px 10px;border-radius:4px;font-size:11px;pointer-events:none;white-space:pre;z-index:10;\"></div>\n",
        "        </div>\n",
        "    </div>\n",
        "    <script>\n",
        "    (function() {{\n",
        "        const canvas = document.getElementById(\"{uid}_canvas\");\n",
        "        const ctx = canvas.getContext(\"2d\");\n",
        "        const tip = document.getElementById(\"{uid}_tip\");\n",
        "        const btnOn = document.getElementById(\"{uid}_on\");\n",
        "        const btnOff = document.getElementById(\"{uid}_off\");\n",
        "        const meta = {json.dumps(cell_meta_js)};\n",
        "        const mask = {json.dumps(mask_small)};\n",
        "        const step = {step};\n",
        "        const W = {W};\n",
        "        const H = {H};\n",
        "        const hasNucleus = {json.dumps(nucleus_png is not None)};\n",
        "        \n",
        "        // Load channel images\n",
        "        const channelImagesData = {json.dumps(channel_imgs_js)};\n",
        "        const channelImages = {{}};\n",
        "        const maskImg = new Image();\n",
        "        const nucleusImg = hasNucleus ? new Image() : null;\n",
        "        let imagesLoaded = 0;\n",
        "        const totalImages = Object.keys(channelImagesData).length + 1 + (hasNucleus ? 1 : 0);\n",
        "        \n",
        "        // Load mask image\n",
        "        maskImg.onload = () => {{\n",
        "            imagesLoaded++;\n",
        "            if (imagesLoaded === totalImages) updateImage();\n",
        "        }};\n",
        "        maskImg.src = \"data:image/png;base64,{mask_png}\";\n",
        "        \n",
        "        // Load nucleus image if available\n",
        "        if (hasNucleus) {{\n",
        "            nucleusImg.onload = () => {{\n",
        "                imagesLoaded++;\n",
        "                if (imagesLoaded === totalImages) updateImage();\n",
        "            }};\n",
        "            nucleusImg.src = \"data:image/png;base64,{nucleus_png if nucleus_png else ''}\";\n",
        "        }}\n",
        "        \n",
        "        // Load channel images\n",
        "        for (const [chIdx, imgSrc] of Object.entries(channelImagesData)) {{\n",
        "            const img = new Image();\n",
        "            img.onload = () => {{\n",
        "                imagesLoaded++;\n",
        "                if (imagesLoaded === totalImages) updateImage();\n",
        "            }};\n",
        "            img.src = imgSrc;\n",
        "            channelImages[chIdx] = img;\n",
        "        }}\n",
        "        \n",
        "        let activeChannels = {json.dumps(initial_active)};\n",
        "        let showMask = true;\n",
        "        let showNucleus = hasNucleus;\n",
        "        \n",
        "        window.toggleChannel = function(channelIdx) {{\n",
        "            const idx = activeChannels.indexOf(channelIdx);\n",
        "            if (idx === -1) {{\n",
        "                activeChannels.push(channelIdx);\n",
        "            }} else {{\n",
        "                activeChannels.splice(idx, 1);\n",
        "            }}\n",
        "            updateImage();\n",
        "            \n",
        "            const btn = document.getElementById(\"{uid}_ch\" + channelIdx);\n",
        "            if (btn) {{\n",
        "                btn.style.background = (idx === -1) ? \"#007bff\" : \"#6c757d\";\n",
        "            }}\n",
        "        }};\n",
        "        \n",
        "        window.toggleMask = function(on) {{\n",
        "            showMask = on;\n",
        "            updateImage();\n",
        "            btnOn.style.background = on ? \"#007bff\" : \"#6c757d\";\n",
        "            btnOff.style.background = on ? \"#6c757d\" : \"#007bff\";\n",
        "        }};\n",
        "        \n",
        "        if (hasNucleus) {{\n",
        "            const btnNucOn = document.getElementById(\"{uid}_nuc_on\");\n",
        "            const btnNucOff = document.getElementById(\"{uid}_nuc_off\");\n",
        "            \n",
        "            window.toggleNucleus = function(on) {{\n",
        "                showNucleus = on;\n",
        "                updateImage();\n",
        "                btnNucOn.style.background = on ? \"#17a2b8\" : \"#6c757d\";\n",
        "                btnNucOff.style.background = on ? \"#6c757d\" : \"#17a2b8\";\n",
        "            }};\n",
        "        }}\n",
        "        \n",
        "        function updateImage() {{\n",
        "            // Clear canvas\n",
        "            ctx.clearRect(0, 0, W, H);\n",
        "            \n",
        "            // Use 'lighter' blend mode for additive compositing (GPU-accelerated!)\n",
        "            ctx.globalCompositeOperation = 'lighter';\n",
        "            \n",
        "            // Draw all active channels with additive blending\n",
        "            for (const chIdx of activeChannels) {{\n",
        "                const img = channelImages[chIdx];\n",
        "                if (img && img.complete) {{\n",
        "                    ctx.drawImage(img, 0, 0, W, H);\n",
        "                }}\n",
        "            }}\n",
        "            \n",
        "            // Draw mask overlay\n",
        "            if (showMask && maskImg.complete) {{\n",
        "                ctx.globalCompositeOperation = 'source-over';\n",
        "                ctx.drawImage(maskImg, 0, 0, W, H);\n",
        "            }}\n",
        "            \n",
        "            // Draw nucleus overlay\n",
        "            if (hasNucleus && showNucleus && nucleusImg && nucleusImg.complete) {{\n",
        "                ctx.globalCompositeOperation = 'source-over';\n",
        "                ctx.drawImage(nucleusImg, 0, 0, W, H);\n",
        "            }}\n",
        "        }}\n",
        "        \n",
        "        canvas.onmousemove = (e) => {{\n",
        "        const rect = canvas.getBoundingClientRect();\n",
        "        const scaleX = W / rect.width;\n",
        "        const scaleY = H / rect.height;\n",
        "        const x = Math.floor((e.clientX - rect.left) * scaleX);\n",
        "        const y = Math.floor((e.clientY - rect.top) * scaleY);\n",
        "        const mx = Math.floor(x / step), my = Math.floor(y / step);\n",
        "        if (my >= 0 && my < mask.length && mx >= 0 && mx < mask[0].length) {{\n",
        "            const id = mask[my][mx];\n",
        "            if (id > 0 && meta[id]) {{\n",
        "                const m = meta[id];\n",
        "                let txt = `Cell ${{m.index}}`;\n",
        "                \n",
        "                // Morphological features\n",
        "                if (m.area != null) txt += `\\\\nArea: ${{m.area.toFixed(1)}}`;\n",
        "                if (m.perimeter != null) txt += `\\\\nPerimeter: ${{m.perimeter.toFixed(1)}}`;\n",
        "                if (m.equivalent_diameter != null) txt += `\\\\nEq Diameter: ${{m.equivalent_diameter.toFixed(2)}}`;\n",
        "                if (m.bbox_width != null) txt += `\\\\nBBox W: ${{m.bbox_width.toFixed(1)}}`;\n",
        "                if (m.bbox_height != null) txt += `\\\\nBBox H: ${{m.bbox_height.toFixed(1)}}`;\n",
        "                if (m.aspect_ratio != null) txt += `\\\\nAspect Ratio: ${{m.aspect_ratio.toFixed(3)}}`;\n",
        "                if (m.circularity != null) txt += `\\\\nCircularity: ${{m.circularity.toFixed(3)}}`;\n",
        "                if (m.eccentricity != null) txt += `\\\\nEccentricity: ${{m.eccentricity.toFixed(3)}}`;\n",
        "                if (m.solidity != null) txt += `\\\\nSolidity: ${{m.solidity.toFixed(3)}}`;\n",
        "                if (m.convexity != null) txt += `\\\\nConvexity: ${{m.convexity.toFixed(3)}}`;\n",
        "                \n",
        "                // Texture features\n",
        "                if (m.brightness != null) txt += `\\\\nBrightness: ${{m.brightness.toFixed(3)}}`;\n",
        "                \n",
        "                // Fluorescence intensity features - show ALL available fields\n",
        "                for (const key in m) {{\n",
        "                    // Cell intensities\n",
        "                    if (key.startsWith('mean_intensity_') && key.endsWith('_cell') && m[key] != null) {{\n",
        "                        const channelName = key.replace('mean_intensity_', '').replace('_cell', '').replace(/_/g, ' ');\n",
        "                        txt += `\\\\n${{channelName}} (cell): ${{m[key].toFixed(1)}}`;\n",
        "                    }}\n",
        "                    // Nucleus intensities\n",
        "                    if (key.startsWith('mean_intensity_') && key.endsWith('_nucleus') && m[key] != null) {{\n",
        "                        const channelName = key.replace('mean_intensity_', '').replace('_nucleus', '').replace(/_/g, ' ');\n",
        "                        txt += `\\\\n${{channelName}} (nuc): ${{m[key].toFixed(1)}}`;\n",
        "                    }}\n",
        "                    // Cytosol intensities\n",
        "                    if (key.startsWith('mean_intensity_') && key.endsWith('_cytosol') && m[key] != null) {{\n",
        "                        const channelName = key.replace('mean_intensity_', '').replace('_cytosol', '').replace(/_/g, ' ');\n",
        "                        txt += `\\\\n${{channelName}} (cyto): ${{m[key].toFixed(1)}}`;\n",
        "                    }}\n",
        "                    // Ratios\n",
        "                    if (key.startsWith('ratio_') && key.endsWith('_nuc_cyto') && m[key] != null) {{\n",
        "                        const channelName = key.replace('ratio_', '').replace('_nuc_cyto', '').replace(/_/g, ' ');\n",
        "                        txt += `\\\\n${{channelName}} (N/C): ${{m[key].toFixed(2)}}`;\n",
        "                    }}\n",
        "                    // Top10 intensities (backward compatible)\n",
        "                    if (key.startsWith('top10_mean_intensity_') && m[key] != null) {{\n",
        "                        const channelName = key.replace('top10_mean_intensity_', '').replace(/_/g, ' ');\n",
        "                        txt += `\\\\nTop 10% ${{channelName}}: ${{m[key].toFixed(1)}}`;\n",
        "                    }}\n",
        "                }}\n",
        "                \n",
        "                tip.textContent = txt;\n",
        "                tip.style.display = \"block\";\n",
        "                tip.style.left = (e.clientX - rect.left + 10) + \"px\";\n",
        "                tip.style.top = (e.clientY - rect.top + 10) + \"px\";\n",
        "                return;\n",
        "            }}\n",
        "        }}\n",
        "        tip.style.display = \"none\";\n",
        "    }};\n",
        "    canvas.onmouseleave = () => {{ tip.style.display = \"none\"; }};\n",
        "    }})();\n",
        "    </script>\n",
        "    '''\n",
        "    asyncio.ensure_future(api.create_window(src=html, name=\"Image Segmentation\"))\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_matplotlib_fig(fig, name: str, dpi: int = 200, max_width: str = \"100%\") -> None:\n",
        "    \"\"\"Display matplotlib figure via asyncio.ensure_future(api.create_window()). DO NOT use plt.show().\"\"\"\n",
        "    buf = BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", dpi=dpi, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "    asyncio.ensure_future(api.create_window(\n",
        "        src=(\n",
        "            f'<div style=\"text-align:center;\">'\n",
        "            f'<img src=\"data:image/png;base64,{b64}\" style=\"max-width:{max_width};\"/>'\n",
        "            f\"</div>\"\n",
        "        ),\n",
        "        name=name\n",
        "    ))\n",
        "\n",
        "# System Prompts, Workflow Templates, and Utility Functions\n",
        "\n",
        "# Build DataFrame utility\n",
        "def build_df_from_records(\n",
        "    records: List[Dict],\n",
        "    *,\n",
        "    distance_key: str = \"distance_from_center\",\n",
        "    well_id_key: str = \"well_id\",\n",
        "    fallback_well_from_position: bool = True,\n",
        "    exclude_keys: Optional[List[str]] = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Convert cell_records to DataFrame with ALL available data fields.\"\"\"\n",
        "    default_exclude = {\n",
        "        \"image\",\n",
        "        \"clip_embedding\",\n",
        "        \"dino_embedding\",\n",
        "    }\n",
        "    \n",
        "    if exclude_keys:\n",
        "        default_exclude.update(exclude_keys)\n",
        "    \n",
        "    def _safe_float(v):\n",
        "        try:\n",
        "            if v is None:\n",
        "                return np.nan\n",
        "            return float(v)\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    \n",
        "    def _safe_value(v):\n",
        "        if v is None:\n",
        "            return None\n",
        "        if isinstance(v, (int, float, str, bool)):\n",
        "            return v\n",
        "        if isinstance(v, dict):\n",
        "            return str(v)\n",
        "        if isinstance(v, (list, tuple)):\n",
        "            if len(v) < 10:\n",
        "                return str(v)\n",
        "            return None\n",
        "        return str(v)\n",
        "\n",
        "    rows = []\n",
        "    for idx, c in enumerate(records):\n",
        "        pos = c.get(\"position\", {}) or {}\n",
        "\n",
        "        wid = c.get(well_id_key, None)\n",
        "        if (wid is None) and fallback_well_from_position:\n",
        "            wr = pos.get(\"well_row\", None)\n",
        "            wc = pos.get(\"well_col\", None)\n",
        "            if (wr is not None) and (wc is not None):\n",
        "                wid = f\"{wr}{wc}\"\n",
        "        if wid is None:\n",
        "            wid = \"well_1\"\n",
        "\n",
        "        d = _safe_float(c.get(distance_key, np.nan))\n",
        "\n",
        "        row = {\n",
        "            \"cell_index\": idx,\n",
        "            \"well_id\": wid,\n",
        "            \"distance_mm\": d,\n",
        "        }\n",
        "        \n",
        "        if pos:\n",
        "            for pos_key, pos_val in pos.items():\n",
        "                if isinstance(pos_val, (int, float)):\n",
        "                    row[pos_key] = _safe_float(pos_val)\n",
        "                else:\n",
        "                    row[pos_key] = pos_val\n",
        "\n",
        "        for key, value in c.items():\n",
        "            if key in default_exclude:\n",
        "                continue\n",
        "            if key == \"position\":\n",
        "                continue\n",
        "            if key == well_id_key and key in row:\n",
        "                continue\n",
        "            \n",
        "            if any(substring in key.lower() for substring in [\n",
        "                \"intensity\", \"area\", \"perimeter\", \"diameter\", \"width\", \"height\",\n",
        "                \"ratio\", \"circularity\", \"eccentricity\", \"solidity\", \"convexity\",\n",
        "                \"brightness\", \"contrast\", \"homogeneity\", \"energy\", \"correlation\",\n",
        "                \"similarity\", \"score\", \"distance\", \"index\"\n",
        "            ]):\n",
        "                row[key] = _safe_float(value)\n",
        "            else:\n",
        "                row[key] = _safe_value(value)\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    if distance_key in df.columns or \"distance_mm\" in df.columns:\n",
        "        df = df[np.isfinite(df[\"distance_mm\"])].copy()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# System Prompts\n",
        "SYSTEM_PROMPT_1 = \"\"\"\n",
        "You are an AI microscope-control agent for Agent-Lens with Vector Database integration.\n",
        "\n",
        "PRIMARY ROLE\n",
        "- Drive the microscope: navigate to wells, autofocus, move to positions (FoVs), snap images (BF + fluorescence), and run scans.\n",
        "- Do on-the-fly analysis: segmentation, single-cell metadata extraction, similarity search, basic plotting/visualization as requested.\n",
        "- variable 'microscope' is the microscope object, 'agent_lens_service' is the agent lens service object. Other variables are defined in the environment already(color_map, fixed_channel_order, microscope_id, etc).\n",
        "\n",
        "STRICT OUTPUT RULES\n",
        "- Respond with ONLY executable Python code for this Jupyter notebook (no prose).\n",
        "- Respond with direct code, do not wrap code in functions or classes.\n",
        "- Any figure/image output MUST be displayed using asyncio.ensure_future(api.create_window(src=html, name=name)) or pre-defined display functions.\n",
        "- DO NOT use 'await api.create_window()' - it will block execution.\n",
        "- DO NOT rely on plt.show() or Display().\n",
        "- For microscope actions, use the provided async tools (await microscope.* / await snap_image / await segment_image / await agent_lens_service.build_cell_records / etc).\n",
        "- Write a linear, top-to-bottom notebook script. DO NOT define new functions or classes unless necessary.\n",
        "- Minimize stdout. Do NOT print large objects (images/arrays, full records lists, full tool schemas, full microscope status dicts).\n",
        "- Only print short progress messages (1 line) and small scalar summaries.\n",
        "\n",
        "WORKING STYLE\n",
        "- Default to minimal steps that answer the user's request.\n",
        "- Reuse existing variables and helper functions already defined in the notebook.\n",
        "- If a request depends on missing prerequisites, create the needed data first, then proceed.\n",
        "\n",
        "DATA CONVENTIONS\n",
        "- color_map is a dict of channel number to RGB tuple (0-255, 0-255, 0-255)\n",
        "- - default \n",
        "color_map = {\n",
        "    \"0\": (1.0, 1.0, 1.0),  # BF: gray\n",
        "    \"1\": (0.0, 0.0, 1.0),  # 405nm: blue\n",
        "    \"2\": (0.0, 1.0, 0.0),  # 488nm: green\n",
        "    \"3\": (1.0, 0.0, 0.0),  # 638nm: red\n",
        "    \"4\": (1.0, 1.0, 0.0),  # 561nm: yellow(simulated)\n",
        "}\n",
        "You can re-define 'color_map' variable based on user instructions\n",
        "- raw_image is multi-channel, list of numpy arrays for different channel.\n",
        "- raw_image and norm_image are always the same shape and channels order. 0: BF, 1: 405nm, 2: 488nm, 3: 638nm, 4: 561nm\n",
        "- cell_records are lists of dicts with fields:\n",
        "  - uuid: Unique cell identifier\n",
        "  - image: merged composite image (50x50). Note: This is empty, you need to use 'agent_lens_service.fetch_cell_data()' to get complete cell data, which includes the image.\n",
        "  - morphology: area, aspect_ratio, circularity, solidity, eccentricity...\n",
        "  - position info: 'position[x]', 'position[y]', 'distance_from_center', 'well_id'\n",
        "  - optional image crops: 'image' (merged composite)\n",
        "  - cell_records intensity features:\n",
        "    * Single mask mode: mean_intensity_<channel>_cell, top10_mean_intensity_<channel>\n",
        "    * Multi-mask mode (when nucleus mask provided):\n",
        "        - mean_intensity_<channel>_cell\n",
        "        - mean_intensity_<channel>_nucleus  \n",
        "        - mean_intensity_<channel>_cytosol\n",
        "        - ratio_<channel>_nuc_cyto (nucleus-to-cytosol ratio)\n",
        "\n",
        "VECTOR DATABASE SIMILARITY SEARCH\n",
        "- Use similarity_search_with_filters() for backward-compatible filtering\n",
        "- Or use agent_lens_service.similarity_search_cells() directly for vector database native search\n",
        "- Supports native metadata filtering using vector database where clause syntax\n",
        "- Returns cells with similarity_score (0-1, higher is more similar)\n",
        "\n",
        "ANALYSIS CAPABILITIES YOU MUST SUPPORT (WHEN ASKED)\n",
        "- Quick inspection: show raw/normalized images; show segmentation overlay; interactive cell viewer (visualize_cells_interactive).\n",
        "- Similarity search: user selects query cell(s) from cell_records; run similarity_search_with_filters or similarity_search_cells; show_similarity_results.\n",
        "- Spatial analysis: plot cell density, morphology metrics, or custom classifications vs distance from well center.\n",
        "- Custom cell classification: user can define subpopulations based on any combination of intensity/morphology features.\n",
        "- Multi-well statistics: aggregate metrics across wells with mean±SEM error bars.\n",
        "- Intensity metric policy: When gating by fluorescence, compute both mean and top10 metrics if available.\n",
        "\n",
        "DISPLAY REQUIREMENT\n",
        "- Any matplotlib figure must be encoded to html and shown via api.create_window(src=html, name=name). # no await\n",
        "\n",
        "DEFAULT SAFETY / HYGIENE\n",
        "- Validate required keys/columns before use; if missing, fall back gracefully.\n",
        "- Close matplotlib figures after saving/encoding.\n",
        "\"\"\"\n",
        "print(SYSTEM_PROMPT_1)\n",
        "\n",
        "print(\"---\")\n",
        "print(f\"The microscope has the following channels: {fixed_channel_order}\")\n",
        "print(\"---\")\n",
        "# Print available tools\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AVAILABLE FUNCTIONS:\")\n",
        "print(\"=\"*80)\n",
        "#print micrscope schema_tool decorator\n",
        "microscope_tools = [json.dumps(tool.__schema__, indent=2) for tool in microscope.values() if callable(tool)]\n",
        "print(f\"This microscope has the following tools: {microscope_tools}\")\n",
        "\n",
        "agent_lens_tools = [json.dumps(tool.__schema__, indent=2) for tool in agent_lens_service.values() if callable(tool)]\n",
        "print(f\"Agent Lens service has the following tools: {agent_lens_tools}\")\n",
        "\n",
        "def print_tool_doc(func):\n",
        "    print(\"---\")\n",
        "    print(f\"Function: {func.__name__}\")\n",
        "    print(func.__doc__)\n",
        "    print(\"---\")\n",
        "\n",
        "\n",
        "print_tool_doc(snap_image)\n",
        "print_tool_doc(percentile_normalize)\n",
        "print_tool_doc(overlay)\n",
        "print_tool_doc(segment_image)\n",
        "print_tool_doc(make_stage_offsets)\n",
        "print_tool_doc(similarity_search_with_filters)\n",
        "print_tool_doc(show_similarity_results)\n",
        "print_tool_doc(show_matplotlib_fig)\n",
        "print_tool_doc(build_df_from_records)\n",
        "print_tool_doc(wait_for_snap_segment_extract)\n",
        "\n",
        "# Workflow Templates\n",
        "SYSTEM_PROMPT_2 = \"\"\"\n",
        "WORKFLOW TEMPLATES\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "0) TAKE A LOOK (Navigate → Focus → Snap → Segment → View)\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "await microscope.navigate_to_well('B', 2, well_plate_type='96')\n",
        "await microscope.reflection_autofocus()\n",
        "\n",
        "# If user asked for Brightfield, 488nm, 561nm channels\n",
        "channel_config = [\n",
        "  {\"channel\": \"BF_LED_matrix_full\", \"exposure_time\": 10, \"intensity\": 20},\n",
        "  {\"channel\": \"Fluorescence_488_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "  {\"channel\": \"Fluorescence_561_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "]\n",
        "\n",
        "raw_image = await snap_image(channel_config)\n",
        "norm_image = percentile_normalize(raw_image) # The channels order is always the same as fixed_channel_order\n",
        "seg_mask = await segment_image(norm_image)\n",
        "\n",
        "# If nucleus channel is available, segment nuclei\n",
        "# nucleus_mask = await segment_image(norm_image[1])  # If user told you 405nm channel is for nucleus, 405nm is always the SECOND channel of 'fixed_channel_order' and 'norm_image', will not changed by channel_config\n",
        "\n",
        "status = await microscope.get_status()\n",
        "cell_records = await agent_lens_service.build_cell_records(\n",
        "    raw_image, seg_mask, status, application_id=\"hypha-agents-notebook\", color_map=color_map\n",
        ")\n",
        "# If nucleus channel is available, segment nuclei\n",
        "# cell_records = await agent_lens_service.build_cell_records(\n",
        "#     raw_image, \n",
        "#     [cell_mask, nucleus_mask],  # Pass as list for multi-mask mode\n",
        "#     status, \n",
        "#     application_id=\"hypha-agents-notebook\",\n",
        "#     color_map=color_map\n",
        "# )\n",
        "\n",
        "await visualize_cells_interactive(\n",
        "  original_image=norm_image,\n",
        "  segmentation_mask=seg_mask,\n",
        "  cell_records=cell_records,\n",
        ")\n",
        "# If nucleus channel is available, visualize nuclei also\n",
        "# await visualize_cells_interactive(\n",
        "#   original_image=norm_image,\n",
        "#   segmentation_mask=[cell_mask, nucleus_mask],\n",
        "#   cell_records=cell_records,\n",
        "# )\n",
        "\n",
        "print(f\"Found {len(cell_records)} cells\")\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "1) FIND SIMILAR CELLS (Backward-Co\n",
        "patible API)\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# Extract query cell\n",
        "query_cell_indices = [81]\n",
        "query_cell_records = [cell_records[i] for i in query_cell_indices if i < len(cell_records)]\n",
        "\n",
        "# Old-style filter configuration (backward compatible)\n",
        "relative_config = {\n",
        "    \"size_tolerance\": 0.4,\n",
        "    \"circularity_tol\": 0.15,\n",
        "    \"eccentricity_tol\": 0.15,\n",
        "    \"solidity_tol\": 0.1,\n",
        "    \"aspect_ratio_tol\": 0.3,\n",
        "}\n",
        "\n",
        "range_config = {} # Default is empty, no range filtering\n",
        "# Example if range is needed\n",
        "# range_config = {\"top10_mean_intensity_Fluorescence_488_nm_Ex_cell\": {\"min\": 15}}\n",
        "\n",
        "\n",
        "\n",
        "similarity_config = {\n",
        "    \"final_score_threshold\": 0.7,\n",
        "}\n",
        "\n",
        "# Use backward-compatible function\n",
        "similar_cells = await similarity_search_with_filters(\n",
        "    query_cell_records=query_cell_records,\n",
        "    relative_config=relative_config,\n",
        "    range_config=range_config,\n",
        "    similarity_config=similarity_config,\n",
        "    n_results=100\n",
        ")\n",
        "\n",
        "print(f\"Found {len(similar_cells)} similar cells\")\n",
        "show_similarity_results(query_cell_records, similar_cells, max_examples=20)\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "1b) FIND SIMILAR CELLS (Direct Vector Database API)\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# Extract query UUIDs\n",
        "query_uuids = [cell[\"uuid\"] for cell in query_cell_records]\n",
        "\n",
        "# Direct Vector Database where clause\n",
        "similar_cells = await agent_lens_service.similarity_search_cells(\n",
        "    query_cell_uuids=query_uuids,\n",
        "    application_id=\"hypha-agents-notebook\",\n",
        "    n_results=100,\n",
        "    metadata_filters={\n",
        "        \"$and\": [\n",
        "            {\"area\": {\"$gt\": 200, \"$lt\": 3000}},\n",
        "            {\"circularity\": {\"$gte\": 0.7}},\n",
        "            {\"top10_mean_intensity_Fluorescence_488_nm_Ex_cell\": {\"$gte\": 15}}\n",
        "        ]\n",
        "    },\n",
        "    similarity_threshold=0.7\n",
        ")\n",
        "\n",
        "show_similarity_results(query_cell_records, similar_cells, max_examples=20)\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "2) SCAN WITH SIMILARITY SEARCH\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "rows = (\"B\", \"C\", \"D\")\n",
        "cols = tuple(range(2, 5))\n",
        "wells = [f\"{row}{col}\" for row in rows for col in cols]\n",
        "\n",
        "grid_size = 3\n",
        "well_offsets = make_stage_offsets(grid_size=grid_size)\n",
        "\n",
        "channel_config = [\n",
        "    {\"channel\": \"Fluorescence_488_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "    {\"channel\": \"Fluorescence_561_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "    {\"channel\": \"BF_LED_matrix_full\", \"exposure_time\": 10, \"intensity\": 20},\n",
        "\n",
        "]\n",
        "\n",
        "all_cell_records = []\n",
        "resp = await agent_lens_service.snap_segment_extract_put_queue(\n",
        "    microscope_id=microscope_id,\n",
        "    channel_config=channel_config,\n",
        "    application_id=application_id,\n",
        "    scale=8,\n",
        "    wells=wells,\n",
        "    well_offset=well_offset,\n",
        "    well_plate_type=\"96\",\n",
        "    nucleus_channel_name=\"Fluorescence_405_nm_Ex\", # If user TOLD you 405nm channel is for nucleus, otherwise None\n",
        "    color_map=color_map,\n",
        ")\n",
        "print(f\"Queued {len(wells)} wells with {len(well_offset)} positions each\")\n",
        "print(f\"Total FoVs: {len(wells) * len(well_offset)} (queue size={resp['queue_size']})\")\n",
        "print(f\"Queuing took {time.time()-t0:.2f}s\")\n",
        "\n",
        "# Wait for all jobs to complete\n",
        "print('Waiting for all snap+segment+extract jobs to finish...')\n",
        "result_cell_records = await wait_for_snap_segment_extract(agent_lens_service)\n",
        "all_cell_records.extend(result_cell_records)\n",
        "\n",
        "print(f'Total cells extracted: {len(all_cell_records)}')\n",
        "\n",
        "# Now search for similar cells\n",
        "similar_cells = await similarity_search_with_filters(\n",
        "    query_cell_records=query_cell_records,\n",
        "    relative_config=relative_config,\n",
        "    range_config=range_config,\n",
        "    similarity_config=similarity_config,\n",
        "    n_results=100\n",
        ")\n",
        "\n",
        "show_similarity_results(query_cell_records, similar_cells, max_examples=20)\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "3) SPATIAL ANALYSIS\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "df = build_df_from_records(all_scanned_cell_records)\n",
        "metric = \"area\"\n",
        "\n",
        "bin_w = 0.25\n",
        "bins = np.arange(0, df[\"distance_mm\"].max() + bin_w, bin_w)\n",
        "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
        "\n",
        "df[\"r_bin\"] = pd.cut(df[\"distance_mm\"], bins=bins, include_lowest=True)\n",
        "\n",
        "per_well = (\n",
        "  df.groupby([\"well_id\", \"r_bin\"])[metric]\n",
        "    .mean()\n",
        "    .unstack(\"r_bin\")\n",
        ")\n",
        "\n",
        "mean_curve = per_well.mean(axis=0).to_numpy()\n",
        "sem_curve = per_well.sem(axis=0, ddof=1).to_numpy()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "ax.errorbar(bin_centers, mean_curve, yerr=sem_curve, marker=\"o\", linewidth=2, capsize=2)\n",
        "ax.set_xlabel(\"Distance from well center (mm)\")\n",
        "ax.set_ylabel(metric)\n",
        "ax.grid(True, alpha=0.25, linestyle=\"--\")\n",
        "show_matplotlib_fig(fig, name=\"Spatial Analysis\")\n",
        "\n",
        "REMINDER\n",
        "- Use show_matplotlib_fig(fig, name=name) to display plots\n",
        "- Use build_df_from_records() for DataFrame creation\n",
        "- Use similarity_search_with_filters() for backward compatibility\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(SYSTEM_PROMPT_2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✓ All functions and templates loaded!\")\n",
        "print(\"✓ Ready for AI agent control\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc4b4e5-8baa-479a-ad03-febdf68b4641",
      "metadata": {
        "collapsed": false,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": false,
        "isOutputVisible": true,
        "trusted": true
      },
      "source": [
        "Switch to U2OS cell data. Move to well B2(96-well plate), run autofocus, and acquire image with BF+488(green color)+561(red color) channel, and show me merged image result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2739,
      "id": "u2os_b2_bf488561",
      "metadata": {
        "collapsed": false,
        "hasOutput": true,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": true,
        "isOutputVisible": true,
        "parent": "9bc4b4e5-8baa-479a-ad03-febdf68b4641",
        "staged": false,
        "trusted": true,
        "userModified": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Switching sample to U2OS_FUCCI and acquiring BF+488+561...\n",
            "Active sample: U2OS_FUCCI\n",
            "Done: merged image displayed in separate window.\n"
          ]
        }
      ],
      "source": [
        "import asyncio, base64, io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Switching sample to U2OS_FUCCI and acquiring BF+488+561...')\n",
        "\n",
        "# Switch to U2OS sample (simulation environment)\n",
        "switch_result = await microscope.switch_sample(sample_name='U2OS_FUCCI')\n",
        "print('Active sample:', switch_result.get('active_sample', 'unknown'))\n",
        "\n",
        "# Navigate to well B2 on 96-well plate and autofocus\n",
        "_ = await microscope.navigate_to_well(row='B', col=2, well_plate_type='96')\n",
        "_ = await microscope.reflection_autofocus()\n",
        "\n",
        "# Configure BF + 488 + 561 channels\n",
        "channel_config = [\n",
        "    {\"channel\": \"BF_LED_matrix_full\", \"exposure_time\": 10, \"intensity\": 20},\n",
        "    {\"channel\": \"Fluorescence_488_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "    {\"channel\": \"Fluorescence_561_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "]\n",
        "\n",
        "# Snap multi-channel image (returns list of numpy arrays matching fixed_channel_order)\n",
        "raw_image = await snap_image(channel_config)\n",
        "\n",
        "# Normalize\n",
        "norm_image = percentile_normalize(raw_image)\n",
        "\n",
        "# Build composite using default color_map (BF gray, 488 green, 561 yellow by default)\n",
        "# Adjust color map so 488=green, 561=red as requested\n",
        "color_map = {\n",
        "    \"0\": (1.0, 1.0, 1.0),  # BF: gray\n",
        "    \"1\": (0.0, 0.0, 1.0),  # 405: blue (unused here)\n",
        "    \"2\": (0.0, 1.0, 0.0),  # 488: green\n",
        "    \"3\": (1.0, 0.0, 0.0),  # 638: red (unused)\n",
        "    \"4\": (1.0, 0.0, 0.0),  # 561: red\n",
        "}\n",
        "\n",
        "# overlay() uses the global fixed_channel_order and channel indices; we pass the full norm_image list\n",
        "composite = overlay(norm_image, color_map=color_map)\n",
        "\n",
        "# Display merged image via show_matplotlib_fig\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.imshow(composite)\n",
        "ax.set_title('Merged BF + 488 (green) + 561 (red) - Well B2')\n",
        "ax.axis('off')\n",
        "\n",
        "show_matplotlib_fig(fig, name='Merged_BF_488_561_B2')\n",
        "plt.close(fig)\n",
        "\n",
        "print('Done: merged image displayed in separate window.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628a602c-8b21-45e6-bbb9-ed88a16be73e",
      "metadata": {
        "collapsed": false,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": false,
        "isOutputVisible": true,
        "trusted": true
      },
      "source": [
        "Run segmentation, extract cell metadata, show me the segmented result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2740,
      "id": "u2os_b2_segmentation",
      "metadata": {
        "collapsed": false,
        "hasOutput": true,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": true,
        "isOutputVisible": true,
        "parent": "628a602c-8b21-45e6-bbb9-ed88a16be73e",
        "trusted": true,
        "userModified": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running segmentation and extracting cell metadata...\n",
            "Cells found: 164\n",
            "Segmentation result and cells viewer displayed.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Running segmentation and extracting cell metadata...')\n",
        "\n",
        "# Run cell segmentation on normalized multi-channel image\n",
        "seg_mask = await segment_image(norm_image)\n",
        "\n",
        "# Get current microscope status for spatial metadata\n",
        "status = await microscope.get_status()\n",
        "\n",
        "# Build cell records with metadata and store embeddings/images in vector DB\n",
        "cell_records = await agent_lens_service.build_cell_records(\n",
        "    image_data_np=raw_image,\n",
        "    segmentation_mask=seg_mask,\n",
        "    microscope_status=status,\n",
        "    application_id=\"hypha-agents-notebook\",\n",
        "    color_map=color_map,\n",
        ")\n",
        "\n",
        "print(f'Cells found: {len(cell_records)}')\n",
        "\n",
        "# Visualize segmentation overlay and enable interactive cell inspection\n",
        "await visualize_cells_interactive(\n",
        "    original_image=norm_image,\n",
        "    segmentation_mask=seg_mask,\n",
        "    cell_records=cell_records,\n",
        ")\n",
        "\n",
        "print('Segmentation result and cells viewer displayed.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23dff274-1184-47ac-955c-80f71583ec97",
      "metadata": {
        "collapsed": false,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": false,
        "isOutputVisible": true,
        "trusted": true
      },
      "source": [
        "Calculate the confluence of the cells in the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2741,
      "id": "confluence_calc_b2",
      "metadata": {
        "collapsed": false,
        "hasOutput": true,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": true,
        "isOutputVisible": true,
        "parent": "23dff274-1184-47ac-955c-80f71583ec97",
        "staged": false,
        "trusted": true,
        "userModified": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating cell confluence from segmentation mask...\n",
            "Cell pixels: 2409088, Total pixels: 9000000\n",
            "Confluence: 26.77%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print('Calculating cell confluence from segmentation mask...')\n",
        "\n",
        "# Ensure seg_mask exists\n",
        "if 'seg_mask' not in globals() or seg_mask is None:\n",
        "    raise RuntimeError('seg_mask is not available. Please run segmentation first.')\n",
        "\n",
        "# Confluence = fraction of image area covered by cells (non-zero pixels in seg_mask)\n",
        "cell_pixels = np.count_nonzero(seg_mask)\n",
        "all_pixels = seg_mask.size\n",
        "confluence = cell_pixels / all_pixels if all_pixels > 0 else 0.0\n",
        "\n",
        "print(f'Cell pixels: {cell_pixels}, Total pixels: {all_pixels}')\n",
        "print(f'Confluence: {confluence*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47cf9085-a94e-4736-930a-12c705a5a26b",
      "metadata": {
        "collapsed": false,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": false,
        "isOutputVisible": true,
        "trusted": true
      },
      "source": [
        "Use cell 126 as the query cell. Starting from the well B3 to B5, scan well-by-well, until find 100 cells with similar morphology and whoe me the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2742,
      "id": "scan_B3_B5_similarity_from_126",
      "metadata": {
        "collapsed": false,
        "hasOutput": true,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": true,
        "isOutputVisible": true,
        "parent": "47cf9085-a94e-4736-930a-12c705a5a26b",
        "staged": false,
        "trusted": true,
        "userModified": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing query cell (index 126) and configuring scan from wells B3-B5...\n",
            "Starting snap+segment+extract queue for wells ['B3', 'B4', 'B5'] with 9 FoVs per well...\n",
            "Queued 3 wells with 9 positions each; queue size=1\n",
            "Waiting for all snap+segment+extract jobs to finish...\n",
            "Waiting for all snap+segment+extract jobs to finish...\n",
            "[3.2s] Processing... queues[snap:0, seg:0, build:0], workers[snap:BUSY], results:0\n",
            "[36.2s] Processing... queues[snap:0, seg:3, build:0], workers[snap:BUSY, seg/build:BUSY], results:41\n",
            "[69.5s] Processing... queues[snap:0, seg:7, build:0], workers[snap:BUSY, seg/build:BUSY], results:87\n",
            "[102.7s] Processing... queues[snap:0, seg:10, build:0], workers[snap:BUSY, seg/build:BUSY], results:137\n",
            "[135.9s] Processing... queues[snap:0, seg:12, build:0], workers[snap:BUSY, seg/build:BUSY], results:217\n",
            "[169.0s] Processing... queues[snap:0, seg:13, build:0], workers[seg/build:BUSY], results:325\n",
            "[202.0s] Processing... queues[snap:0, seg:7, build:0], workers[seg/build:BUSY], results:502\n",
            "[235.1s] Processing... queues[snap:0, seg:4, build:0], workers[seg/build:BUSY], results:618\n",
            "✓ Complete in 269.1s! Got 709 cell records\n",
            "Total cells extracted in B3-B5 scan: 709\n",
            "Similarity search returned 17 cells; will display up to 100.\n",
            "Similarity results viewer displayed (query cell 126 + similar cells).\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "print('Preparing query cell (index 126) and configuring scan from wells B3-B5...')\n",
        "\n",
        "# Validate query cell index\n",
        "query_index = 126\n",
        "if 'cell_records' not in globals() or len(cell_records) == 0:\n",
        "    raise RuntimeError('cell_records not available. Please run initial segmentation and metadata extraction first.')\n",
        "if query_index >= len(cell_records):\n",
        "    raise IndexError(f'Requested cell index {query_index} but only {len(cell_records)} cells available.')\n",
        "\n",
        "query_cell_records = [cell_records[query_index]]\n",
        "\n",
        "# Define wells B3-B5\n",
        "rows = (\"B\",)\n",
        "cols = tuple(range(3, 6))  # 3,4,5\n",
        "wells = [f\"{row}{col}\" for row in rows for col in cols]\n",
        "\n",
        "# Use a modest 3x3 grid per well\n",
        "grid_size = 3\n",
        "well_offset = make_stage_offsets(grid_size=grid_size)\n",
        "\n",
        "channel_config = [\n",
        "    {\"channel\": \"Fluorescence_488_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "    {\"channel\": \"Fluorescence_561_nm_Ex\", \"exposure_time\": 100, \"intensity\": 60},\n",
        "    {\"channel\": \"BF_LED_matrix_full\", \"exposure_time\": 10, \"intensity\": 20},\n",
        "]\n",
        "\n",
        "application_id = \"hypha-agents-notebook\"\n",
        "\n",
        "print(f'Starting snap+segment+extract queue for wells {wells} with {len(well_offset)} FoVs per well...')\n",
        "\n",
        "# Queue scanning jobs\n",
        "resp = await agent_lens_service.snap_segment_extract_put_queue(\n",
        "    microscope_id=microscope_id,\n",
        "    channel_config=channel_config,\n",
        "    application_id=application_id,\n",
        "    scale=8,\n",
        "    wells=wells,\n",
        "    well_offset=well_offset,\n",
        "    well_plate_type=\"96\",\n",
        "    nucleus_channel_name=None,\n",
        "    color_map=color_map,\n",
        ")\n",
        "\n",
        "print(f\"Queued {len(wells)} wells with {len(well_offset)} positions each; queue size={resp['queue_size']}\")\n",
        "\n",
        "# Wait for completion using helper\n",
        "print('Waiting for all snap+segment+extract jobs to finish...')\n",
        "scanned_cell_records = await wait_for_snap_segment_extract(agent_lens_service)\n",
        "print(f'Total cells extracted in B3-B5 scan: {len(scanned_cell_records)}')\n",
        "\n",
        "# Configure similarity search to target morphology only, and we will later collect at least 100 similar cells\n",
        "relative_config = {\n",
        "    \"size_tolerance\": 0.4,\n",
        "    \"circularity_tol\": 0.15,\n",
        "    \"eccentricity_tol\": 0.15,\n",
        "    \"solidity_tol\": 0.1,\n",
        "    \"aspect_ratio_tol\": 0.3,\n",
        "}\n",
        "\n",
        "range_config = {}\n",
        "\n",
        "similarity_config = {\n",
        "    \"final_score_threshold\": 0.7,\n",
        "}\n",
        "\n",
        "# Run similarity search – ask for more than 100 and we will cap at 100\n",
        "n_results_requested = 200\n",
        "\n",
        "similar_cells = await similarity_search_with_filters(\n",
        "    query_cell_records=query_cell_records,\n",
        "    relative_config=relative_config,\n",
        "    range_config=range_config,\n",
        "    similarity_config=similarity_config,\n",
        "    application_id=application_id,\n",
        "    n_results=n_results_requested,\n",
        ")\n",
        "\n",
        "print(f\"Similarity search returned {len(similar_cells)} cells; will display up to 100.\")\n",
        "\n",
        "# Limit to 100 cells (plus the query which show_similarity_results includes separately)\n",
        "max_to_show = 100\n",
        "\n",
        "show_similarity_results(query_cell_records, similar_cells[:max_to_show], max_examples=max_to_show)\n",
        "\n",
        "print('Similarity results viewer displayed (query cell 126 + similar cells).')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0325d82-77bf-44c2-a17c-dfda23157488",
      "metadata": {
        "collapsed": false,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": false,
        "isOutputVisible": true,
        "trusted": true
      },
      "source": [
        "Here's some biology context about the sample:\n",
        "These cells are U2OS FUCCI. Please classify cell cycle phases using nuclear green and red intensity like this:\n",
        "- G1 = red high, green low\n",
        " - S = both high\n",
        " - G2/M = green high, red low\n",
        "\n",
        "Please use a reasonable threshold automatically, then compare the phase fractions between retrived cells vs all scanned cells in a stacked percentage bar chart. Also show a green vs red scatter, highlighting retrived cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2743,
      "id": "phase_classification_and_plots",
      "metadata": {
        "collapsed": false,
        "hasOutput": true,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": true,
        "isOutputVisible": true,
        "parent": "b0325d82-77bf-44c2-a17c-dfda23157488",
        "staged": false,
        "trusted": true,
        "userModified": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building DataFrame from all scanned cells and retrieved similar cells...\n",
            "DataFrame built. Rows: 709 Retrieved cells: 13\n",
            "Using intensity columns -> Green: mean_intensity_Fluorescence_488_nm_Ex_cell , Red: mean_intensity_Fluorescence_561_nm_Ex_cell\n",
            "Red threshold: 6.371, Green threshold: 7.106\n",
            "Phase fractions (all cells):\n",
            "phase\n",
            "G1       0.303244\n",
            "S        0.097320\n",
            "G2/M     0.303244\n",
            "Other    0.296192\n",
            "Name: proportion, dtype: float64\n",
            "Phase fractions (retrieved cells):\n",
            "phase\n",
            "G1       0.384615\n",
            "S        0.000000\n",
            "G2/M     0.076923\n",
            "Other    0.538462\n",
            "Name: proportion, dtype: float64\n",
            "Phase comparison bar chart and intensity scatter displayed.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "print('Building DataFrame from all scanned cells and retrieved similar cells...')\n",
        "\n",
        "if 'scanned_cell_records' not in globals() or len(scanned_cell_records) == 0:\n",
        "    raise RuntimeError('No scanned_cell_records available from B3-B5 scan.')\n",
        "\n",
        "if 'similar_cells' not in globals() or len(similar_cells) == 0:\n",
        "    raise RuntimeError('No similar_cells available from previous similarity search.')\n",
        "\n",
        "# Build DF from all scanned cells\n",
        "df_all = build_df_from_records(scanned_cell_records)\n",
        "\n",
        "# Extract UUIDs of retrieved similar cells\n",
        "retrieved_uuids = set()\n",
        "for c in similar_cells:\n",
        "    # similar_cells entries may be dicts with 'uuid' or nested metadata\n",
        "    if isinstance(c, dict):\n",
        "        if 'uuid' in c:\n",
        "            retrieved_uuids.add(c['uuid'])\n",
        "        elif 'cell' in c and isinstance(c['cell'], dict) and 'uuid' in c['cell']:\n",
        "            retrieved_uuids.add(c['cell']['uuid'])\n",
        "\n",
        "if not retrieved_uuids:\n",
        "    raise RuntimeError('Could not find UUIDs in similar_cells structure.')\n",
        "\n",
        "# Annotate DF with whether each row is retrieved\n",
        "df_all['is_retrieved'] = df_all['uuid'].isin(retrieved_uuids)\n",
        "\n",
        "print('DataFrame built. Rows:', len(df_all), 'Retrieved cells:', df_all['is_retrieved'].sum())\n",
        "\n",
        "# Identify available intensity columns for green (488) and red (561)\n",
        "possible_green = [\n",
        "    'mean_intensity_Fluorescence_488_nm_Ex_cell',\n",
        "    'top10_mean_intensity_Fluorescence_488_nm_Ex_cell',\n",
        "]\n",
        "possible_red = [\n",
        "    'mean_intensity_Fluorescence_561_nm_Ex_cell',\n",
        "    'top10_mean_intensity_Fluorescence_561_nm_Ex_cell',\n",
        "]\n",
        "\n",
        "green_col = next((c for c in possible_green if c in df_all.columns), None)\n",
        "red_col = next((c for c in possible_red if c in df_all.columns), None)\n",
        "\n",
        "if green_col is None or red_col is None:\n",
        "    raise RuntimeError(f'Missing required intensity columns. Green from {possible_green}, Red from {possible_red}.')\n",
        "\n",
        "print('Using intensity columns -> Green:', green_col, ', Red:', red_col)\n",
        "\n",
        "# Drop rows with NaNs in intensity\n",
        "mask_valid = df_all[green_col].notna() & df_all[red_col].notna()\n",
        "df_all = df_all.loc[mask_valid].copy()\n",
        "\n",
        "# Compute automatic thresholds using percentiles (e.g., 60th percentile)\n",
        "red_thresh = np.percentile(df_all[red_col], 60)\n",
        "green_thresh = np.percentile(df_all[green_col], 60)\n",
        "\n",
        "print(f'Red threshold: {red_thresh:.3f}, Green threshold: {green_thresh:.3f}')\n",
        "\n",
        "# Classify phases\n",
        "conds = []\n",
        "labels = []\n",
        "\n",
        "# G1: red high, green low\n",
        "conds.append((df_all[red_col] >= red_thresh) & (df_all[green_col] < green_thresh))\n",
        "labels.append('G1')\n",
        "\n",
        "# S: both high\n",
        "conds.append((df_all[red_col] >= red_thresh) & (df_all[green_col] >= green_thresh))\n",
        "labels.append('S')\n",
        "\n",
        "# G2/M: green high, red low\n",
        "conds.append((df_all[green_col] >= green_thresh) & (df_all[red_col] < red_thresh))\n",
        "labels.append('G2/M')\n",
        "\n",
        "phase = np.full(len(df_all), 'Other', dtype=object)\n",
        "for cond, lab in zip(conds, labels):\n",
        "    phase[cond.values] = lab\n",
        "\n",
        "df_all['phase'] = phase\n",
        "\n",
        "# Compute phase fractions for all vs retrieved\n",
        "phase_order = ['G1', 'S', 'G2/M', 'Other']\n",
        "\n",
        "fractions_all = df_all['phase'].value_counts(normalize=True).reindex(phase_order, fill_value=0)\n",
        "fractions_retrieved = df_all.loc[df_all['is_retrieved'], 'phase'].value_counts(normalize=True).reindex(phase_order, fill_value=0)\n",
        "\n",
        "print('Phase fractions (all cells):')\n",
        "print(fractions_all)\n",
        "print('Phase fractions (retrieved cells):')\n",
        "print(fractions_retrieved)\n",
        "\n",
        "# Create stacked percentage bar chart\n",
        "x = np.arange(2)  # 0: all, 1: retrieved\n",
        "\n",
        "fig1, ax1 = plt.subplots(figsize=(5, 4))\n",
        "\n",
        "bottom_all = 0\n",
        "bottom_ret = 0\n",
        "colors = {\n",
        "    'G1': '#d62728',   # red\n",
        "    'S': '#9467bd',    # purple\n",
        "    'G2/M': '#2ca02c', # green\n",
        "    'Other': '#7f7f7f' # gray\n",
        "}\n",
        "\n",
        "for ph in phase_order:\n",
        "    fa = fractions_all[ph] * 100\n",
        "    fr = fractions_retrieved[ph] * 100\n",
        "    if fa == 0 and fr == 0:\n",
        "        continue\n",
        "    ax1.bar(0, fa, bottom=bottom_all, color=colors.get(ph, '#cccccc'), label=ph if bottom_all == 0 else \"\")\n",
        "    ax1.bar(1, fr, bottom=bottom_ret, color=colors.get(ph, '#cccccc'))\n",
        "    bottom_all += fa\n",
        "    bottom_ret += fr\n",
        "\n",
        "ax1.set_xticks([0, 1])\n",
        "ax1.set_xticklabels(['All scanned', 'Retrieved'])\n",
        "ax1.set_ylabel('Fraction of cells (%)')\n",
        "ax1.set_ylim(0, 100)\n",
        "ax1.set_title('Cell cycle phase fractions')\n",
        "ax1.legend(title='Phase', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "show_matplotlib_fig(fig1, name='Phase_Fractions_Stacked_Bar')\n",
        "plt.close(fig1)\n",
        "\n",
        "# Scatter plot: green vs red, highlighting retrieved cells\n",
        "fig2, ax2 = plt.subplots(figsize=(5, 4))\n",
        "\n",
        "# All cells (background)\n",
        "ax2.scatter(df_all[green_col], df_all[red_col], s=8, alpha=0.3, c='lightgray', label='All scanned')\n",
        "\n",
        "# Retrieved cells highlighted\n",
        "retr = df_all['is_retrieved']\n",
        "ax2.scatter(df_all.loc[retr, green_col], df_all.loc[retr, red_col],\n",
        "            s=12, alpha=0.8, c='orange', edgecolor='k', linewidth=0.3, label='Retrieved similar')\n",
        "\n",
        "# Threshold lines\n",
        "ax2.axvline(green_thresh, color='green', linestyle='--', linewidth=1)\n",
        "ax2.axhline(red_thresh, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "ax2.set_xlabel(f'Green (488) intensity [{green_col}]')\n",
        "ax2.set_ylabel(f'Red (561) intensity [{red_col}]')\n",
        "ax2.set_title('Green vs Red intensity with retrieved cells highlighted')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "show_matplotlib_fig(fig2, name='Green_vs_Red_Scatter_Retrieved')\n",
        "plt.close(fig2)\n",
        "\n",
        "print('Phase comparison bar chart and intensity scatter displayed.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a1cd665-a5b9-402c-9b95-e553b234b851",
      "metadata": {
        "collapsed": false,
        "isCodeVisible": true,
        "isEditing": false,
        "isNew": false,
        "isOutputVisible": true,
        "trusted": true
      },
      "source": [
        "Show violin plots comparing retrived vs all scanned for mophology metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2745,
      "id": "morphology_violin_plots",
      "metadata": {
        "collapsed": false,
        "hasOutput": true,
        "isCodeVisible": false,
        "isEditing": false,
        "isNew": true,
        "isOutputVisible": true,
        "parent": "7a1cd665-a5b9-402c-9b95-e553b234b851",
        "staged": false,
        "trusted": true,
        "userModified": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating violin plots for morphology metrics (retrieved vs all scanned)...\n",
            "Metrics to plot: ['area', 'equivalent_diameter', 'aspect_ratio', 'circularity', 'eccentricity', 'solidity', 'convexity', 'bbox_width', 'bbox_height']\n",
            "Violin plots displayed.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print('Generating violin plots for morphology metrics (retrieved vs all scanned)...')\n",
        "\n",
        "# Ensure df_all with is_retrieved exists\n",
        "if 'df_all' not in globals():\n",
        "    raise RuntimeError('df_all DataFrame with scanned cells is not available.')\n",
        "\n",
        "# Candidate morphology metrics\n",
        "morph_metrics = ['area', 'equivalent_diameter', 'aspect_ratio', 'circularity',\n",
        "                 'eccentricity', 'solidity', 'convexity', 'bbox_width', 'bbox_height']\n",
        "\n",
        "available_metrics = [m for m in morph_metrics if m in df_all.columns]\n",
        "if not available_metrics:\n",
        "    raise RuntimeError('No morphology metrics found in DataFrame columns.')\n",
        "\n",
        "print('Metrics to plot:', available_metrics)\n",
        "\n",
        "# Prepare data subsets\n",
        "all_mask = np.ones(len(df_all), dtype=bool)\n",
        "retr_mask = df_all['is_retrieved'].astype(bool).values\n",
        "\n",
        "# Create violin plots, one figure with subplots\n",
        "n_metrics = len(available_metrics)\n",
        "cols = 3\n",
        "rows = int(np.ceil(n_metrics / cols))\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3*rows), squeeze=False)\n",
        "\n",
        "for idx, metric in enumerate(available_metrics):\n",
        "    r = idx // cols\n",
        "    c = idx % cols\n",
        "    ax = axes[r, c]\n",
        "\n",
        "    data_all = df_all.loc[all_mask, metric].dropna().values\n",
        "    data_ret = df_all.loc[retr_mask, metric].dropna().values\n",
        "\n",
        "    # Skip if not enough data\n",
        "    if len(data_all) < 2 or len(data_ret) < 2:\n",
        "        ax.text(0.5, 0.5, 'Insufficient data', ha='center', va='center')\n",
        "        ax.set_title(metric)\n",
        "        ax.set_xticks([])\n",
        "        continue\n",
        "\n",
        "    parts = ax.violinplot([data_all, data_ret], positions=[1, 2], showmeans=True, showextrema=False)\n",
        "\n",
        "    # Color violins\n",
        "    for i, body in enumerate(parts['bodies']):\n",
        "        if i == 0:\n",
        "            body.set_facecolor('#1f77b4')  # blue for all\n",
        "        else:\n",
        "            body.set_facecolor('#ff7f0e')  # orange for retrieved\n",
        "        body.set_alpha(0.6)\n",
        "\n",
        "    if 'cmeans' in parts:\n",
        "        parts['cmeans'].set_color('k')\n",
        "        parts['cmeans'].set_linewidth(1.0)\n",
        "\n",
        "    ax.set_xticks([1, 2])\n",
        "    ax.set_xticklabels(['All', 'Retrieved'])\n",
        "    ax.set_title(metric)\n",
        "    ax.grid(alpha=0.3, linestyle='--')\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(n_metrics, rows*cols):\n",
        "    r = j // cols\n",
        "    c = j % cols\n",
        "    axes[r, c].axis('off')\n",
        "\n",
        "fig.suptitle('Morphology metrics: All scanned vs Retrieved similar cells', y=0.99)\n",
        "fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "\n",
        "show_matplotlib_fig(fig, name='Morphology_Violin_All_vs_Retrieved')\n",
        "plt.close(fig)\n",
        "\n",
        "print('Violin plots displayed.')\n"
      ]
    }
  ],
  "metadata": {
    "agentArtifact": {
      "description": "A code assistant powered by Hypha Agent Lab",
      "id": "",
      "name": "reef",
      "version": "1.0.0"
    },
    "created": "2026-01-12T10:08:24.715Z",
    "environmentVariables": [],
    "filePath": "agent-lens-hpa-demo.ipynb",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    },
    "modelSettings": {
      "apiKey": "sk-***********************",
      "baseURL": "https://api.openai.com/v1/",
      "model": "gpt-4o",
      "temperature": 0.7
    },
    "modified": "2026-03-01T21:29:11.171Z",
    "projectId": "in-browser",
    "title": "reef"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
